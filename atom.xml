<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Next Legend!</title>
  
  <subtitle>一天进步一点点</subtitle>
  <link href="/NextLegend.github.io/atom.xml" rel="self"/>
  
  <link href="https://legendtianjin.github.io/NextLegend.github.io/"/>
  <updated>2018-09-27T13:08:53.757Z</updated>
  <id>https://legendtianjin.github.io/NextLegend.github.io/</id>
  
  <author>
    <name>赵小亮</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习100天</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/09/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0100%E5%A4%A9/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/09/27/机器学习100天/</id>
    <published>2018-09-27T12:49:16.000Z</published>
    <updated>2018-09-27T13:08:53.757Z</updated>
    
    <content type="html"><![CDATA[<p><center><font color="black" size="8"><strong>机器学习100天</strong></font></center><br>&#160; &#160; &#160; &#160;小亮接触深度学习也将近一年了，通过走了这么多的路，读论文也好，看视频也好，看书也好，<strong>发现还是得通过边敲代码边思考边理解公式这样的方式比较踏实</strong>，不然就是天马行空，吹吹牛罢了！你会什么？我会深度学习耶！那你给我写两行代码解决一下这个问题？感知机是什么？交叉熵损失函数是什么？反向转播算法来推导一下？Pandas、Numpy、Scikit-learn这些库用过吗？<strong>当面试官或者HR问起这些的时候，我希望小亮或者你们能够胸有成竹的说，这些我都会哈，来我给你手工推导一下交叉熵损失函数是如何影响网络的学习速率的，反向传播算法是根据微积分的链式求导罚则调节参数权重w和偏置b的，这个项目我做过，那个我也知道。。。。。。其实，这个时候这种状态才是小亮应有的状态，希望在2020年毕业的时候，再回到此处时，可以做到无悔于时间、无悔于现在所做的一切与努力。每天进步一点点，来跟着小亮Machine Learning吧！</strong><br><img src="/NextLegend.github.io/2018/09/27/机器学习100天/001.JPG" alt="机器学习100天"><br><img src="/NextLegend.github.io/2018/09/27/机器学习100天/002.JPG" alt="机器学习100天"><br><img src="/NextLegend.github.io/2018/09/27/机器学习100天/003.JPG" alt="机器学习100天"><br><img src="/NextLegend.github.io/2018/09/27/机器学习100天/004.JPG" alt="机器学习100天"><br><img src="/NextLegend.github.io/2018/09/27/机器学习100天/005.JPG" alt="机器学习100天"><br>&#160; &#160; &#160; &#160;<strong>上面的是机器学习100天的每天的内容，从今天开始，小亮将会身体力行的实践，边思考边前行边总结边记录每一天的成长与收获！欢迎各位小伙伴与小亮一起前行，不断地打怪升级！</strong></p>]]></content>
    
    <summary type="html">
    
      今天是2018年9月27日，距离2019年春节还有96天的时间，小100天。小亮开始了Machine_Learning_100_days的学习，今天先介绍一下自己的学习计划与课程相关内容，欢迎大家与小亮实时交流哈！
    
    </summary>
    
      <category term="Machine_Learning Python" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Machine-Learning-Python/"/>
    
    
      <category term="机器学习" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>NLP事件检测基本概念</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/09/25/NLP%E4%BA%8B%E4%BB%B6%E6%A3%80%E6%B5%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/09/25/NLP事件检测基本概念/</id>
    <published>2018-09-25T13:39:42.000Z</published>
    <updated>2018-09-25T14:17:10.959Z</updated>
    
    <content type="html"><![CDATA[<p><center><font color="black" size="16"><strong>自然语言处理之事件检测</strong></font></center><br><strong>一、什么是NLP</strong><br>&#160; &#160; &#160; &#160;nlp是自然语言处理，是电脑理解并表达出人们平常的所说的语言<br><strong>二、nlp的事件抽取是什么？</strong><br>&#160; &#160; &#160; &#160;事件抽取是从非结构信息中抽取出用户感兴趣的信息，并以结构化数据传递给用户。<br><strong>三、事件抽取所处的位置？</strong><br>&#160; &#160; &#160; &#160;事件抽取是信息抽取的一部分。事件抽取的又分为元事件抽取和主题事件抽取。元事件抽取是动作状态级的，动作产生或状态发生变化，一般由动词驱动。主题事件抽取是事件级的，一类核心事件或活动以及与他们相关的事件和活动。<br><strong>四、事件抽取的研究方法有哪些？</strong><br>&#160; &#160; &#160; &#160;事件抽取的研究方法有模式匹配和机器学习两种。模式匹配只针对特定领域，移植性差。机器学习应用广泛，移植性好。<br><strong>五、模式匹配方法如何进行事件抽取？</strong><br>&#160; &#160; &#160; &#160;模式匹配方法是在一定模式的指导下进行事件的识别和抽取。<br>模式：指的是抽取模式。通过领域知识和语言知识对目标信息的上下文环境进行约束。而这约束条件就是抽取模式。另外模式是手工建立的，耗时又费力，所以现在用的都是机器学习方法的事件抽取。<br><strong>六、机器学习方法如何进行事件抽取？</strong><br>&#160; &#160; &#160; &#160;对元事件抽取两大主要任务：对事件识别与分类和对事件元素进行识别和分类。事件元素识别和分类是事件识别和分类的基础。有关论文显示：机器学习算法混合使用将优于单一算法。事件的探测分两种实现方式：基于触发词的探测方式和基于事件的事例的探测方式。<br>&#160; &#160; &#160; &#160;基于触发词的探测方式：<br>&#160; &#160; &#160; &#160;基于触发词的探测方式的有正反例不平衡和数据稀疏的缺点。因为只有少量触发词作为输入数据进行训练，大量未参与进来的。作为反例数据参与到模型中，造成正反例不平衡，触发词数据稀疏。解决触发词探测缺点的方法：通过同义词扩展和二分类结合的方法进行解决，即将触发词放入词典中进行同义词扩展。<br>&#160; &#160; &#160; &#160;基于事件实例的探测方式：<br>&#160; &#160; &#160; &#160;基于事件实例的探测方式是将句子而不是词语作为识别实例。进而通过聚类方法转化为句子聚类问题，通过聚类得到事件句。避开了基于触发词探测的缺点。<br><strong>七、基于机器学习方法抽取方式的特点？</strong><br>&#160; &#160; &#160; &#160;(1) 机器学习方法的优点是自动获取模式。<br>&#160; &#160; &#160; &#160;(2) 机器学习方法不基于语料的格式和内容，但需要大量标准预料（解决方法:无监督和半监督的方法）</p>]]></content>
    
    <summary type="html">
    
      今天和明天小亮要整理NLP事件抽取方向的各个顶会Paper，梳理一下知识点找一些idea 所以今天先给大家普及一下自然语言处理领域中事件检测方向的一些基本概念等等！
    
    </summary>
    
      <category term="NLP Event Detection" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/NLP-Event-Detection/"/>
    
    
      <category term="NLP" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>这里的人与这里的故事</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/09/09/%E8%BF%99%E9%87%8C%E7%9A%84%E4%BA%BA%E4%B8%8E%E8%BF%99%E9%87%8C%E7%9A%84%E6%95%85%E4%BA%8B/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/09/09/这里的人与这里的故事/</id>
    <published>2018-09-09T14:11:16.000Z</published>
    <updated>2018-09-09T16:07:05.728Z</updated>
    
    <content type="html"><![CDATA[<p>&#160; &#160; &#160; &#160;在记录自己今天的感受前，先来介绍一下我大学仅有的几个好朋友之一———&gt;<strong>老郭</strong>（也就是今天的主人公李同学）！<strong>我和老郭的认识源于电子设计比赛，认知于电子设计比赛，结交于电子设计比赛，虽然我们不是一个班的，但是我们在很多问题上交流的很多，从他身上也学到了很多为人处世的道理——&gt;谦逊、踏实、担当，还有感恩！</strong><br>&#160; &#160; &#160; &#160;早上十点钟我们本来约定在大学城地铁站见面，但是很巧的是，在营口道转3号线的时候，小亮竟然与老郭完美的偶遇于一趟车的相邻车厢。（这就是缘分！哈哈！）上车后第一眼就看到了他，远远地看去，瘦了一圈，可能是来自于工作的压力人就会瘦吧！身穿一件深灰色的衬衣与牛仔裤，戴着耳机，（程序员可能都是这样的装备吧！）也在寻觅着我。老郭还是老郭，还是那样的幽默风趣，还是那样的思考着前行着前行着而又思考着，其实小亮心里一直挺为他惋惜的，但是一直又鼓励着他，让他自信起来，相信自己，不要因为过去的事带着自卑的情绪而影响现在的自己，因为你值得更好地未来，没错，你值得！！！我们俩就像失散多年的老友一样，还是当年的那个老郭与于谦，相谈甚欢。<br>&#160; &#160; &#160; &#160;到了大学城地铁站，我建议骑个小黄去学院吧，老郭说咱们走过去吧，我说好，这样也可以用脚步重新再走一遍这个地方。<strong>于是，我们就顶着今天的太阳，感受着校庆60周年的余热，北门的一句“欢迎校友回家”甚是暖心，是啊，才毕业不到三个月的我们，已然是这所大学的校友，感叹时间过得如此的飞快，老郭突然冒出一句：“下一次回到这里就不知道是什么时候了，或许在十年后吧！”我紧接着附和道：“是啊，可能是十年后了吧！”之所以与老郭的关系不断深入，就是因为知道他的每一句话背后的故事，以及他在想什么，而他所想的同时也是我想的，或许这就是我们能够说到一块的原因吧。此刻，他又在感叹，感叹曾经的故事！</strong>走在宽大的校园马路上，随处可见工大60周年校庆的牌子，还挺美的，与大家分享一下哈！<br><img src="/NextLegend.github.io/2018/09/09/这里的人与这里的故事/004.jpg" alt="这里的人与这里的故事"><br>&#160; &#160; &#160; &#160;走到这里的时候，突然有三四个中年阿姨，问我们：“同学，你知道校史馆怎么走吗？”我和老郭给这些校友前辈指了校史馆的位置，老郭说要不咱们也去看看吧，之前我没去过，我说好。就这样，我们作为年轻校友在前面给校友前辈带路，到了校史馆，我和老郭在前面观看学校的历史与珍贵的仪器，顺便听讲着学生讲解员给她们的讲解。<strong>在走到一台上了年纪的纺织仪器面前，老郭出于一贯的质疑与好奇思维，尝试着搞明白它的机械原理（被我偷拍了，哈哈）</strong><br><img src="/NextLegend.github.io/2018/09/09/这里的人与这里的故事/001.jpg" alt="这里的人与这里的故事"><br>&#160; &#160; &#160; &#160;<strong>还有这个—————&gt;</strong><br><img src="/NextLegend.github.io/2018/09/09/这里的人与这里的故事/002.jpg" alt="这里的人与这里的故事"><br>&#160; &#160; &#160; &#160;在经过时间里程计的时候，我突然握住老郭的大手，我说一起见证这伟大的时刻吧，而老郭突然配乐道：“当当当当。。。。。。”我禁不住笑了起来，你这是瓦格纳的《婚礼进行曲》啊，有点尴尬，哈哈。<br><img src="/NextLegend.github.io/2018/09/09/这里的人与这里的故事/003.jpg" alt="这里的人与这里的故事"><br>&#160; &#160; &#160; &#160;参观完校史馆，我们迫不及待的赶紧前往学院，先去了老师办公室，结果发现没人，可能是周末的原因吧。。。。。。。。然后我们就去考研自习室找了会煜大神，时间也十一点了，我们商量着要不先去吃饭去吧，就边走边聊，老郭和会煜大神谈起来更是津津有味，他们两更是同道中人。<strong>（这次回来，发现大家都没怎么变，还是老样子，真切、幽默、调侃、又互相关心着彼此的发展，或许这就是好朋友最真的面貌吧！）吃饭回来在学院一楼又聊了聊，聊到了过去，聊到了现在，还聊到了未来。</strong><br>&#160; &#160; &#160; &#160;聊到了大概十二点半左右，我和老郭看着时间也不早了，不能影响了会煜大神的节奏，我们就与他告别离开了，<strong>希望今年他能够考上自己心仪的学校，也是我们专业，甚至学院最有希望与能力的。其实，自己从他那里也学到了很多很多，做事态度认真，求真务实、追求完美、说话只说自己很有把握的话，给人一种非常踏实的感觉与印象，就是每一件事都交给他，让人很放心，而且他不仅会完成任务，而且还会给你优化与一些建议，这就是他，会煜大神，关于他的故事已然成为我们专业，乃至学院的神话，人人皆知，人人皆视其为榜样！</strong><br>&#160; &#160; &#160; &#160;再后来，我和老郭联系了一下老师，老师说他刚到办公室，我们去办公室找他，就这样，我和老郭准备了半个小时就去看望老师了。和老师谈了两三个小时，谈到了过去，谈到了现在，谈到了未来。谈到了学业、谈到了工作、谈到了个人理想。老郭又有些感触了，(我总觉得他有些不甘心，有些自卑)老师似乎也发现了，就鼓励他说其实做技术积累个两三年也挺好的，现在的研究生动手能力太差了，连最基本的仪器都不会使用，到时候找工作就不如你们这些已经工作了两三年的，只是他们起点比你们现在高罢了，老郭听后觉得也有道理，目光些许明亮起来，给老师说，他有这个自信能够在单位里做好。<strong>（以老郭的能力与思维能力，我相信三五年后，或许我该叫他李所或者李部长了。）后来又和老师聊了很多，老师也相应的给了一些建议，让我们不管在社会上还是学校里，都要实事求是，踏踏实实做技术，规划好自己的时间与人生，该来的总会来的，要懂得隐忍与坚守！！！</strong><br>&#160; &#160; &#160; &#160;四点左右，我和老郭看着时间不早了，也不想打扰老师工作（周末老师还来实验室，可见他的敬业与乐业精神所在）我们就和老师道别后，离开了。<br>&#160; &#160; &#160; &#160;<strong>最后想说，自己虽然现在已是一名研究生了，两年半后自己也面临着找工作，进入社会这个象牙塔，到时候是以怎样的姿态以及怎样的精神面貌迎接那时候的社会与工作，全在这不到三年里的每一天的进步与成长，就像老郭一样，思考着前行着前行着而又思考着，生活就是这样。人生路上能够遇到这样的恩师很难得，也很庆幸自己能够在求学路上遇见很多这样的恩师，古语云：“十年树木，百年树人；插柳之恩；终生难忘！”最后，明天是教师节，提前预祝天下的所有教师节日快乐！</strong></p><p><div align="right"> <strong>——2018年9月9日夜晚 于天津大学北洋园</strong></div></p>]]></content>
    
    <summary type="html">
    
      今天是2018年9月9日，明天是9月10日教师节，昨天小亮的大学同学兼比赛队长再兼相声老郭（哈哈，我给他取的，因为他说话自带天津的相声幽默风味）和小亮商量着今天一起去看望大学老师，今天重新回到这个待了四年，至今不愿去回忆的地方，再次坚定自己当初的选择与坚守！！！
    
    </summary>
    
      <category term="朋友 人生导师" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E6%9C%8B%E5%8F%8B-%E4%BA%BA%E7%94%9F%E5%AF%BC%E5%B8%88/"/>
    
    
      <category term="人生路上的朋友" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/%E4%BA%BA%E7%94%9F%E8%B7%AF%E4%B8%8A%E7%9A%84%E6%9C%8B%E5%8F%8B/"/>
    
  </entry>
  
  <entry>
    <title>计算图上的微积分：反向传播</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/09/05/%E8%AE%A1%E7%AE%97%E5%9B%BE%E4%B8%8A%E7%9A%84%E5%BE%AE%E7%A7%AF%E5%88%86%EF%BC%9A%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/</id>
    <published>2018-09-05T13:36:14.000Z</published>
    <updated>2018-09-05T13:46:36.296Z</updated>
    
    <content type="html"><![CDATA[<p><strong>一、介绍</strong><br>反向传播是一种关键的算法，它可以使训练深度模型在计算上易于处理。对于现代神经网络来说，相对于一个简单的实现，它可以使梯度下降的训练速度达到1000万倍。这就是一周训练和用20万年时间训练的模型之间的区别。<br>除了在深度学习中使用之外，反向传播在许多其他领域是一个强大的计算工具，从天气预报到分析数字稳定性，它只是在不同的领域用不同的名字。事实上，该算法在不同的领域至少被重新改造了几十次（见Griewank（2010））。一般，应用程序独立，名称是“反向模式区分”。<br>从根本上说，这是一种快速计算微分的技术。在你的包里，这是一个很重要的技巧，不仅在深度学习中，而且在各种各样的数字计算环境中。<br><strong>二、计算图</strong><br>计算图是一种思考数学表达式的好方法。例如，考虑表达式e =(a + b)∗(b + 1)。这里有三个操作：两个加法和一个乘法。为了帮助我们讨论这个问题，让我们引入两个中间变量，<br>c和d，所以每个函数的输出都有一个变量。我们现在有:<br>                            c=a + b<br>                            d=b + 1<br>                            e=c * d<br>为了创建一个计算图，我们将这些操作连同输入变量一起放入节点。当一个节点的值是另一个节点的输入时，一个箭头从一个节点到另一个节点。<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/001.png" alt="计算图上的微积分：反向传播"><br>在计算机科学中，这些图表一直都在出现，尤其是在谈论功能程序的时候。它们与依赖关系图和调用图的概念密切相关。它们也是流行的深度学习框架Theano背后的核心抽象。<br>我们可以通过将输入变量设置为特定的值和通过图表计算节点来评估表达式。例如,让我们设置a = 2和b = 1 :<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/002.png" alt="计算图上的微积分：反向传播"><br>表达式的求值结果为6。<br><strong>三、计算图的导数</strong><br>如果想要在计算图中理解导数，关键是要理解导数的边界。如果a直接影响c，然后我们想知道它是如何影响的c。如果a稍微改变一下，那c如何改变?我们称其c是关于a的偏导数。<br>为了求出这张图中的偏导数，我们需要求和规则和乘积法则：<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/003.png" alt="计算图上的微积分：反向传播"><br>下图中每条边都有导数。<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/004.png" alt="计算图上的微积分：反向传播"><br>如果我们想要了解没有直接连接的节点是如何相互影响的呢？让我们考虑一下e是如何被a影响的。如果我们以1的速度改变a，c同样的变化速度1改变。反过来, c以1的速度变化导致e以2的改变速率。所以e变化速率1∗2关于a。一般规则是对从一个节点到另一个节点的所有可能路径求和，将路径的每个边的导数相乘。例如，要得到e关于b的导数。我们得到:<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/005.png" alt="计算图上的微积分：反向传播"><br>这就解释了b是如何影响e到c的，以及它是如何通过d来影响它的。这种一般的“对路径求和”规则只是一种不同的关于多元链式法则的思考方式。<br><strong>四、因式分解路径</strong><br>仅仅“对路径求和”的问题是，在可能的路径中，很容易得到一个组合爆炸。<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/006.png" alt="计算图上的微积分：反向传播"><br>在上面的图中，从X到Y有三条路径，从Y到Z还有三条路径。如果我们想求导∂Z/∂X的话，通过对所有路径求和，我们需要求和3∗3 = 9条道路:<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/007.png" alt="计算图上的微积分：反向传播"><br>上面只有9条路径，但是当图形变得更加复杂时，很容易就会有成倍增长的路径。与其简单地对路径求和，不如把它们因式分解：<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/008.png" alt="计算图上的微积分：反向传播"><br>这就是“前向传播”和“反向传播”。它们是通过分解路径来有效计算总和的算法。它们不是显式地对所有路径求和，而是通过在每个节点上合并路径来更有效地计算相同的总和。事实上，这两种算法都能精确地触碰到每条边！ 前向传播从图的输入开始，然后向末端移动。在每个节点上，它都能计算出所有的路径。每条路径都代表了输入影响该节点的一种方式。通过把它们加起来，我们得到了节点受输入影响的总方式，它是导数。<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/009.png" alt="计算图上的微积分：反向传播"><br>虽然你可能没有从图的角度来考虑它，但是向前模式的微分和你在微积分课上做过的介绍是非常相似的。另一方面，反向传播的微分，从图的输出开始，向开始移动。在每个节点上，它合并了源自该节点的所有路径。<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/010.png" alt="计算图上的微积分：反向传播"><br>前向传播微分研究一个输入如何影响每个节点。反向传播微分研究每个节点如何影响一个输出。也就是说，正向模式微分应用算子∂/∂X对每个节点，反向模式微分应用算子∂Z/∂每一个节点。<br><strong>五、Computational Victories</strong><br>在这一点上，您可能想知道为什么有人会关心反向传播的微分。这看起来像是一种奇怪的方法，可以做与前模一样的事情。有什么好处吗？让我们再来看看我们最初的例子：<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/011.png" alt="计算图上的微积分：反向传播"><br>我们可以使用正向模式的微分b向上，这就给了我们每个结点的导数b。<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/012.png" alt="计算图上的微积分：反向传播"><br>我们计算∂e/∂b，这个导数是我们的输出对我们的输入的导数。如果我们做反向模式的微分从e开始? 这就得到了e对于每个节点的微分。<br><img src="/NextLegend.github.io/2018/09/05/计算图上的微积分：反向传播/013.png" alt="计算图上的微积分：反向传播"><br>当我说反向传播微分给我们对每个结点的导数时，我确实是指每个结点。我们得到两个∂e/∂a和∂e/∂b，e的导数是关于两个输入。前向传播的微分给了我们输出对单个输入的导数，但是反向模式的微分给了我们所有的结果。对于这个图，这只是两个因子的加速，但是想象一个有上百万个输入和一个输出的函数。前向传播的微分要求我们通过这个图上百万次来得到导数。反向传播的微分可以一下子把它们都弄到手！一个百万分之一的速度是相当不错的！在训练神经网络时，我们考虑的是成本（描述神经网络的糟糕程度）作为参数的函数（描述网络行为的数字）。我们想要计算所有参数的成本的导数，用于梯度下降。现在，在神经网络中，通常有数百万甚至数千万个参数。所以，反向模式的分化，在神经网络的背景下被称为反向传播，给我们一个巨大的速度！<br>（有任何情况下，正向模式的分化更有意义吗？是的,有! 当反向模式给出一个输出对所有输入的导数时，正向模式给出了所有输出对一个输入的导数。如果一个函数有大量的输出，那么正向模式的微分就会大大加快。)<br><strong>六、这不是简单的吗?</strong><br>Isn’t This Trivial?<br>当我第一次理解反向传播的时候，我的反应是：“哦，这就是链式法则！我们怎么花了这么长时间才弄明白？“我不是唯一一个有这种反应的人。”的确，如果你问“在前馈神经网络中有一种聪明的计算导数的方法吗？”“答案并不难。<br>但我认为这比表面上看起来要困难得多。你看，在反向传播发明的时候，人们并不是很关注我们研究的前馈神经网络。同样不明显的是，微分是培训它们的正确方式。一旦你意识到你可以快速计算出导数，这些就很明显了。这是一种循环依赖。<br>更糟糕的是，在不经意的想法中，把循环依赖的任何部分都写下来是很容易的。用微分工具训练神经网络？你肯定会被困在局部最优解里。很明显，计算所有这些导数都很昂贵。这只是因为我们知道这种方法是有效的，我们不会立即开始列出它可能不会的原因。<br>这是事后诸葛亮的好处。一旦你提出了这个问题，最困难的工作就已经完成了。<br><strong>七、结论</strong><br>微分比你想象的要便宜。这是我们从这篇文章中得到的主要教训。事实上，它们的价格并不便宜，而美国愚蠢的人不得不反复发现这一事实。在深度学习中，这是很重要的一点。在其他领域中，这也是一件非常有用的事情，只有当它不是常识的时候才会知道。还有其他的教训吗？我认为有。反向传播也是理解微分如何流经模型的有用工具。这对于解释为什么有些模型很难优化是非常有用的。最典型的例子是在重复的神经网络中消失的梯度问题。最后，我认为从这些技术中可以得到一个广泛的算法教训。反向传播和正向模式的区别使用强大的一对技巧（线性化和动态规划）来比人们想象的更有效地计算导数。如果您真正理解了这些技术，您可以使用它们来有效地计算其他涉及到微分的有趣表达式。我们将在以后的博客文章中探讨这个问题。这篇文章给出了一个非常抽象的反向传播的方法。我强烈建议阅读Michael Nielsen关于它的章节，进行精彩的讨论，更具体地关注神经网络。<br><strong>八、致谢</strong><br>感谢Greg Corrado，Jon Shlens，Samy Bengio和an利亚Angelova，感谢他们花时间校对这篇文章。也要感谢达里奥阿米迪、迈克尔尼尔森和约书亚本吉奥讨论解释反向传播的方法。也要感谢那些在演讲和研讨会系列中允许我练习解释反向传播的人！</p>]]></content>
    
    <summary type="html">
    
      小亮最近在看以色列大佬的NLP书籍《Neural Network Methods for Natural Language Processing》这里是第五章里面的内容中的推荐部分：关于微分的资料，详情请见下文！
    
    </summary>
    
      <category term="计算图 神经网络" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E8%AE%A1%E7%AE%97%E5%9B%BE-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="神经网络" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>再谈数据结构</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/09/05/%E5%86%8D%E8%B0%88%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/09/05/再谈数据结构/</id>
    <published>2018-09-05T12:22:02.000Z</published>
    <updated>2018-09-05T13:06:35.841Z</updated>
    
    <content type="html"><![CDATA[<p><strong>我把书籍PDF版本和配套代码放在我的百度云里，附上链接地址：</strong><br><strong>百度云链接：<a href="https://pan.baidu.com/s/1dp9K-KljcZoctUL37yCvWg" target="_blank" rel="noopener">https://pan.baidu.com/s/1dp9K-KljcZoctUL37yCvWg</a> 密码：43po</strong><br>小亮的同学（栗同学）在大学和小亮是一个专业的，研究生申请到了法国格勒诺布尔大学，（很优秀哈）。先介绍一下这个大学哈：<br>格勒诺布尔大学集团（格勒诺布尔-阿尔卑斯大学）是一所拥有近七百年历史的国立研究型大学，其科研实力处于法国顶尖水平，诞生过两位诺贝尔奖获得者（克劳斯·冯·克利青Klaus von Klitzing，路易·奈尔Louis Néel），一位图灵奖获得者（Joseph Sifakis），同时也是联合国教科文组织国际传播学教席（Chaire UNESCO）所在处。<br><strong>院校声誉：具有世界影响力的法国顶尖大学</strong><br>优势专业：自然科学、医学、社会与人文科学、语言学、信息传播学<br><strong>中国教育部是否认证：获得认证</strong><br>全球排名：<br><strong>CWUR（2018）世界大学排名第97位 </strong><br>USNews世界大学排名 （2018）全球大学排名第146位<br>ARWU （2017）世界大学学术排名第152位<br>THE（2018）泰晤士高等教育世界大学排名第301-350位<br>QS（2018）世界大学排名第236位<br>韦伯麦特里克斯网(Webometrics)世界大学（2018）排名第295名<br><strong>下面是这个学校的校园，是不是很美呐！！！</strong><br><img src="/NextLegend.github.io/2018/09/05/再谈数据结构/001.png" alt="再谈数据结构"><br><img src="/NextLegend.github.io/2018/09/05/再谈数据结构/002.jpg" alt="再谈数据结构"><br><img src="/NextLegend.github.io/2018/09/05/再谈数据结构/003.jpg" alt="再谈数据结构"><br><strong>好啦，言归正传！下面介绍：数据结构PDF与配套代码-C语言-严蔚敏</strong><br><img src="/NextLegend.github.io/2018/09/05/再谈数据结构/004.jpg" alt="再谈数据结构"><br><strong>小亮将大学上数据结构（C语言）这门课的课件和实验也单独整理出来了，放在一个文件夹中（数据结构PPT），分享给大家！（如果大家觉得不和胃口，可以忽略这个文件夹，直接跳转到下面的文件夹哈。）</strong><br><img src="/NextLegend.github.io/2018/09/05/再谈数据结构/005.png" alt="再谈数据结构"><br><strong>然后是《数据结构(C语言版).严蔚敏_吴伟民》扫描版PDF和本书的配套代码，如下图所示:</strong><br><img src="/NextLegend.github.io/2018/09/05/再谈数据结构/008.png" alt="再谈数据结构"><br><img src="/NextLegend.github.io/2018/09/05/再谈数据结构/006.png" alt="再谈数据结构"><br><img src="/NextLegend.github.io/2018/09/05/再谈数据结构/007.png" alt="再谈数据结构"><br><strong>一点点感受：其实，数据结构小亮觉得非常重要，他强调逻辑的严密性和算法的高效性。最近小亮的师兄也在找工作——&gt;机器学习方向算法岗，亲身感受到了算法基础的重要性，而算法又不是短期内能够提升的，贵在平时的积累与代码实践，所以小亮特意整理了这些资料，分享给技术小伙伴们！</strong></p>]]></content>
    
    <summary type="html">
    
      小亮今天和去法国读研的大学同学聊了聊，他需要数据结构C语言版本的资料，我就整理了一下，毕竟算法岗位很讲究逻辑的严谨性和规则，数据结构很重要的。详情请见下文！
    
    </summary>
    
      <category term="数据结构 C语言 算法" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-C%E8%AF%AD%E8%A8%80-%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据结构" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>汉字拼音转换工具_Python版</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/09/03/%E6%B1%89%E5%AD%97%E6%8B%BC%E9%9F%B3%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7-Python%E7%89%88/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/09/03/汉字拼音转换工具-Python版/</id>
    <published>2018-09-03T13:39:48.000Z</published>
    <updated>2018-09-04T03:01:48.198Z</updated>
    
    <content type="html"><![CDATA[<p>环境配置：<br>Wn10+CPU i7-6700<br>Pycharm 2018<br>python 3.6<br>numpy 1.14.5<br><strong>一、github介绍</strong><br><strong>先附上github的一张图片哈：</strong><br><img src="/NextLegend.github.io/2018/09/03/汉字拼音转换工具-Python版/001.jpg" alt="汉字拼音转换工具_Python版"><br><strong>github地址如下：</strong><br><strong><a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener">https://github.com/mozillazg/python-pinyin</a></strong><br><strong>二、特性</strong><br>(1) 根据词组智能匹配最正确的拼音。<br>(2) 支持多音字。<br>(3) 简单的繁体支持, 注音支持。<br>(4) 支持多种不同拼音/注音风格。<br><strong>三、安装</strong><br><strong>注意：以下两种安装方式选择其一即可</strong><br>1、pip安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install pypinyin</span><br></pre></td></tr></table></figure></p><p>2、pycharm安装<br><img src="/NextLegend.github.io/2018/09/03/汉字拼音转换工具-Python版/003.png" alt=""><br><img src="/NextLegend.github.io/2018/09/03/汉字拼音转换工具-Python版/004.png" alt=""><br><strong>四、代码实践</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> pypinyin <span class="keyword">import</span> pinyin, lazy_pinyin, Style</span><br><span class="line"></span><br><span class="line">value1 = pinyin(<span class="string">'天津大学'</span>)</span><br><span class="line">print(value1)</span><br><span class="line"></span><br><span class="line">value2 = pinyin(<span class="string">'天津大学'</span>, heteronym=<span class="keyword">True</span>)  <span class="comment"># 启用多音字模式</span></span><br><span class="line">print(value2)</span><br><span class="line"></span><br><span class="line">value3 =  pinyin(<span class="string">'天津大学'</span>, style=Style.FIRST_LETTER)  <span class="comment"># 设置拼音风格</span></span><br><span class="line">print(value3)</span><br><span class="line"></span><br><span class="line">value4 = pinyin(<span class="string">'天津大学'</span>, style=Style.TONE2, heteronym=<span class="keyword">True</span>)</span><br><span class="line">print(value4)</span><br><span class="line"></span><br><span class="line">value5 = pinyin(<span class="string">'天津大学'</span>, style=Style.BOPOMOFO)  <span class="comment"># 注音风格</span></span><br><span class="line">print(value5)</span><br><span class="line"></span><br><span class="line">value6 = pinyin(<span class="string">'天津大学'</span>, style=Style.CYRILLIC)  <span class="comment"># 俄语字母风格</span></span><br><span class="line">print(value6)</span><br><span class="line"></span><br><span class="line">value7 = lazy_pinyin(<span class="string">'天津大学'</span>)  <span class="comment"># 不考虑多音字的情况</span></span><br><span class="line">print(value7)</span><br></pre></td></tr></table></figure></p><p><strong>五、实验结果</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[&apos;tiān&apos;], [&apos;jīn&apos;], [&apos;dà&apos;], [&apos;xué&apos;]]</span><br><span class="line">[[&apos;tiān&apos;], [&apos;jīn&apos;], [&apos;dà&apos;], [&apos;xué&apos;]]</span><br><span class="line">[[&apos;t&apos;], [&apos;j&apos;], [&apos;d&apos;], [&apos;x&apos;]]</span><br><span class="line">[[&apos;tia1n&apos;], [&apos;ji1n&apos;], [&apos;da4&apos;], [&apos;xue2&apos;]]</span><br><span class="line">[[&apos;ㄊㄧㄢ&apos;], [&apos;ㄐㄧㄣ&apos;], [&apos;ㄉㄚˋ&apos;], [&apos;ㄒㄩㄝˊ&apos;]]</span><br><span class="line">[[&apos;тянь1&apos;], [&apos;цзинь1&apos;], [&apos;да4&apos;], [&apos;сюэ2&apos;]]</span><br><span class="line">[&apos;tian&apos;, &apos;jin&apos;, &apos;da&apos;, &apos;xue&apos;]</span><br></pre></td></tr></table></figure></p><p><img src="/NextLegend.github.io/2018/09/03/汉字拼音转换工具-Python版/002.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      小亮今天看到一个不错的项目，现在和大家分享一下哈！该项目是基于hotoo/pinyin开发。将汉字转为拼音，可以用于汉字注音、排序、检索(Russian translation) 。详情请见下文！
    
    </summary>
    
      <category term="Python NLP" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Python-NLP/"/>
    
    
      <category term="NLP" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>2018算法工程师秋招集锦</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/09/03/2018%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%A7%8B%E6%8B%9B%E9%9B%86%E9%94%A6/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/09/03/2018算法工程师秋招集锦/</id>
    <published>2018-09-03T11:38:35.000Z</published>
    <updated>2018-09-03T11:38:35.441Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Learning Pyspark</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/25/Learning-Pyspark/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/25/Learning-Pyspark/</id>
    <published>2018-08-25T02:37:09.000Z</published>
    <updated>2018-08-25T03:35:58.810Z</updated>
    
    <content type="html"><![CDATA[<p><strong>我把书籍PDF版本和配套代码放在我的百度云里，附上链接地址：</strong><br><strong>百度云链接：<a href="https://pan.baidu.com/s/1EogSZ3mT4tAYZyqj6WprIg" target="_blank" rel="noopener">https://pan.baidu.com/s/1EogSZ3mT4tAYZyqj6WprIg</a> 密码：vsmv</strong><br><strong>下面介绍一下这本书：Learning Pyspark</strong><br><img src="/NextLegend.github.io/2018/08/25/Learning-Pyspark/Learning_Pyspark.png" alt="Learning Pyspark"></p><p>感谢您选择本书开始您的PySpark冒险，我希望您像我一样兴奋。当DennyLee第一次告诉我这本新书的时候很高兴 - 使Apache Spark成为最重要的事情之一精彩的平台，支持Java / Scala / JVM世界和Python（以及最近的R）世界。许多以前针对Spark的书都是专注于所有核心语言，或主要关注JVM语言，所以很高兴看到PySpark有机会用这样的专用书来发光经验丰富的Spark教育家。通过支持这两个不同的世界，我们是能够更有效地作为数据科学家和数据工程师一起工作窃取彼此社区的最佳想法。能够有机会审查其早期版本是一种荣幸这本书，只是增加了我对这个项目的兴奋。我有这个特权参加一些相同的会议和聚会，并观看作者向各种受众介绍Spark世界的新概念（从第一部分开始）定时器到老手），他们做了很好的工作，提炼他们的经验这本书。作者的经验从他们的作品中汲取了一切对所涉及主题的解释。除了简单介绍PySpark之外，他们还有还花时间查看来自社区的新闻包，例如GraphFrames和TensorFrames。我认为社区是决定时经常被忽视的组件之一使用什么工具，Python有一个很棒的社区，我很期待您加入了PythonSpark社区。所以，享受你的冒险;我知道你是与Denny Lee和TomekDrabas保持良好关系。我真的相信这一点一个多样化的Spark用户社区，我们将能够制作更好的工具。大家好，所以我希望能在一次会议，聚会或邮寄中见到你很快列出:)霍尔顿卡劳<br>附：<br>我欠丹尼一杯啤酒;如果你想给我买一个Bud Light lime（或lime-a-rita）我非常感激（虽然他可能不像我那样有趣）.<br><strong>本书作者：Tomasz Drabas</strong><br>Tomasz Drabas是一名为微软工作的数据科学家，目前居住在微软西雅图地区。 他在数据分析和数据科学方面拥有超过13年的经验在众多的领域：先进技术，航空公司，电信，金融，他在三大洲工作时获得了咨询：欧洲，澳大利亚，和北美。 在澳大利亚期间，Tomasz一直在攻读他的博士学位运营研究，重点关注选择建模和收益管理航空业的应用。</p>]]></content>
    
    <summary type="html">
    
      该书籍为2017年由Tomasz Drabas出版的英文原版Learning Pyspark。书籍技术路线是：在本地构建数据密集型应用程序并部署大规模使用Python和Spark 2.0的组合功能。
    
    </summary>
    
      <category term="Spark" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Spark/"/>
    
    
      <category term="大数据" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Python之禅</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/Python%E4%B9%8B%E7%A6%85/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/Python之禅/</id>
    <published>2018-08-24T13:47:44.000Z</published>
    <updated>2018-08-24T13:50:01.292Z</updated>
    
    <content type="html"><![CDATA[<p><strong>The Zen of Python, by Tim Peters</strong><br>Beautiful is better than ugly.<br>Explicit is better than implicit.<br>Simple is better than complex.<br>Complex is better than complicated.<br>Flat is better than nested.<br>Sparse is better than dense.<br>Readability counts.<br>Special cases aren’t special enough to break the rules.<br>Although practicality beats purity.<br>Errors should never pass silently.<br>Unless explicitly silenced.<br>In the face of ambiguity, refuse the temptation to guess.<br>There should be one– and preferably only one –obvious way to do it.<br>Although that way may not be obvious at first unless you’re Dutch.<br>Now is better than never.<br>Although never is often better than <em>right</em> now.<br>If the implementation is hard to explain, it’s a bad idea.<br>If the implementation is easy to explain, it may be a good idea.<br>Namespaces are one honking great idea – let’s do more of those!</p><p><strong>Tim Peters的Python之禅</strong><br>美丽胜过丑陋。<br>显式优于隐式。<br>简单比复杂更好。<br>复杂比复杂更好。<br>Flat优于嵌套。<br>稀疏优于密集。<br>可读性很重要。<br>特殊情况不足以打破规则。<br>虽然实用性胜过纯洁。<br>错误不应该默默地传递。<br>除非明确沉默。<br>面对模棱两可，拒绝猜测的诱惑。<br>应该有一个 - 最好只有一个 - 显而易见的方法。<br>虽然这种方式起初可能并不明显，除非你是荷兰人。<br>现在总比没有好。<br>虽然现在永远不会比*正确好。<br>如果实施很难解释，那是个坏主意。<br>如果实现很容易解释，那可能是个好主意。<br>命名空间是一个很棒的主意 - 让我们做更多的事情吧！</p>]]></content>
    
    <summary type="html">
    
      Tim Peters的Python之禅
    
    </summary>
    
      <category term="Python" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>GAN的理解与TensorFlow的实现</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/GAN%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8ETensorFlow%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/GAN的理解与TensorFlow的实现/</id>
    <published>2018-08-24T07:32:48.000Z</published>
    <updated>2018-08-24T09:54:54.959Z</updated>
    
    <content type="html"><![CDATA[<p>笔者信息：Next_Legend  QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络 高维信息处理<br>                                                                                                                                                                                                                                                                              ——2018.7.31于天津大学<br>一、前言<br>本文会从头介绍生成对抗式网络的一些内容，从生成式模型开始说起，到GAN的基本原理，InfoGAN，AC-GAN的基本科普，如果有任何有错误的地方，请随时喷，我刚开始研究GAN这块的内容，希望和大家一起学习。<br>二、生成式模型<br>何为生成式模型？在很多machine learning的教程或者公开课上，通常会把machine learning的算法分为两类： 生成式模型、判别式模型；其区别在于： 对于输入x，类别标签y，在生成式模型中估计其联合概率分布，而判别式模型估计其属于某类的条件概率分布。 常见的判别式模型包括：LogisticRegression， SVM, Neural Network等等，生成式模型包括：Naive Bayes， GMM， Bayesian Network， MRF 等等。<br>三、研究生成式模型的意义<br>生成式模型的特性主要包括以下几个方面：<br>    在应用数学和工程方面，生成式模型能够有效地表征高维数据分布；<br>    生成式模型能够作为一种技术手段辅助强化学习，能够有效表征强化学习模型中的state状态(这里不扩展，后面会跟RL的学习笔记)；<br>    对semi-supervised learning也有比较好的效果，能够在miss data下训练模型，并在miss data下给出相应地输出；<br>    在对于一个输入伴随多个输出的场景下，生成式模型也能够有效工作，而传统的机器学习方法通过最小化模型输出和期望输出的某个object function的值 无法训练单输入多输出的模型，而生成式模型，尤其是GAN能够hold住这种场景，一个典型的应用是通过场景预测video的下一帧。<br>生成式模型一些典型的应用：<br>    图像的超分辨率<br>    iGAN：Generative Visual Manipulation on the Natural Image Manifold<br>    图像转换<br>四、生成式模型族谱<br><img src="https://img-blog.csdn.net/20180804190740652?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>上图涵盖了基本的生成式模型的方法，主要按是否需要定义概率密度函数分为：<br>Explicit density models<br>explicit density models 又分为tractable explicit models和逼近的explicit model，怎么理解呢，tractable explicit model通常可以直接通过数学方法来建模求解，而基于逼近的explicit model通常无法直接对数据分布进行建模，可以利用数学里的一些近似方法来做数据建模， 通常基于逼近的explicit model分为确定性（变分方法：如VAE的lower bound）和随机性的方法（马尔科夫链蒙特卡洛方法）。<br>    VAE lower bound：<br>    <img src="https://img-blog.csdn.net/20180804190904726?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>    马尔科夫链蒙特卡洛方法（MCMC），一种经典的基于马尔科夫链的抽样方法，通过多次来拟合分布。比较好的教程：A Beginner’s Guide to Monte Carlo Markov Chain MCMC Analysis, An Introduction to MCMC for Machine Learning.<br>Implicit density models<br>无需定义明确的概率密度函数，代表方法包括马尔科夫链、生成对抗式网络（GAN），该系列方法无需定义数据分布的描述函数。</p><p>五、生成对抗式网络与其他生成式网络对比<br>生成对抗式网络（GAN）能够有效地解决很多生成式方法的缺点，主要包括：</p><ul><li>并行产生samples；</li><li>生成式函数的限制少，如无需合适马尔科夫采样的数据分布（Boltzmann machines），生成式函数无需可逆、latent code需与sample同维度（nonlinear ICA）；</li><li>无需马尔科夫链的方法（Boltzmann machines， GSNs）；</li><li>相对于VAE的方法，无需variational bound；<br>GAN比其他方法一般来说性能更好。</li><li>可以使用冒号来定义对齐方式：</li></ul><p>六、GAN工作原理<br>GAN主要由两部分构成：generator和discriminator，generator主要是从训练数据中产生相同分布的samples，而discriminator 则是判断输入是真实数据还是generator生成的数据，discriminator采用传统的监督学习的方法。这里我们可以这样类比，generator 是一个伪造假币的专业人士，discriminator是警察，generator的目的是制造出尽可能以假乱真的假钞，而discriminator是为了能 鉴别是否为假钞，最终整个gan会达到所谓的纳什均衡，Goodfellow在他的paperGAN的理解与TF的实现-小石头的码疯窝中有严格的数学证明，当$p_G$==$p_{data}$时达到 全局最优：<br><img src="https://img-blog.csdn.net/20180804191235601?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>另一个比较明显看得懂的图如下：<br><img src="https://img-blog.csdn.net/20180804191312769?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>图中黑色点线为真实数据分布$p_{data}$，绿色线为generator生成的数据分布$p_{G}$,而Discriminator就是蓝色点线，其目的是为了将$p_{data}$和$p_{G}$ 区分，(a)中是初始状态，然后会更新Discriminator中的参数，若干次step之后，Discriminator有了较大的判断力即到了(b)的状态，之后会更新G的模型使其生成的数据分布（绿色线）更加趋近与真实数据分布， 若干次G和D的模型参数更新后，理论上最终会达到(d)的状态即G能够产生和真实数据完全一致的分布(证明见上一张图)，如从随机数据分布生成人脸像。<br>七、如何训练GAN<br>因为GAN结构的不同，和常规训练一个dl model方法不同， 这里采用simultaneous SGD，每一个step中，会有两个两个梯度优化的 过程，一个是更新discriminator的参数来最小化$J_{(D)}$，一个是更新generator的参数来最小$J_{(G)}$，通常会选用Adam来作为最优化的优化器， 也有人建议可以不等次数地更新generator和discriminator（有相关工作提出，1：1的在实际中更有效：Adam: A Method for Stochastic Optimization） 如何训练GAN，在Goodfellow的GAN的tutorial还有一些代码中有更多的描述包括不同的cost function， 这里我就不详细展开了。<br>1、DCGAN<br>GAN出来后很多相关的应用和方法都是基于DCGAN的结构，DCGAN即”Deep Convolution GAN”，通常会有一些约定俗成的规则：<br><img src="https://img-blog.csdn.net/20180804191418817?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><ul><li>在Discriminator和generator中大部分层都使用batch normalization，而在最后一层时通常不会使用batch normalizaiton，目的 是为了保证模型能够学习到数据的正确的均值和方差；</li><li>因为会从random的分布生成图像，所以一般做需要增大图像的空间维度时如77-&gt;1414， 一般会使用strdie为2的deconv（transposed convolution）；</li><li>通常在DCGAN中会使用Adam优化算法而不是SGD。<br>2、各种GAN<br><img src="https://img-blog.csdn.net/2018080419152318?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>这里有个大神把各种gan的paper都做了一个统计AdversarialNetsPapers<br>这里大家有更多的兴趣可以直接去看对应的paper，我接下来会尽我所能描述下infogan和AC-GAN这两块的内容<br>3、InfoGAN<br>InfoGAN是一种能够学习disentangled representation的GAN，何为disentangled representation？比如人脸数据集中有各种不同的属性特点，如脸部表情、是否带眼睛、头发的风格眼珠的颜色等等，这些很明显的相关表示， InfoGAN能够在完全无监督信息（是否带眼睛等等）下能够学习出这些disentangled representation，而相对于传统的GAN，只需修改loss来最大化GAN的input的noise（部分fixed的子集）和最终输出之间的互信息。<br>4、原理<br>为了达到上面提到的效果，InfoGAN必须在input的noise来做一些文章，将noise vector划分为两部分：</li><li>z: 和原始的GAN input作用一致；</li><li>c: latent code，能够在之后表示数据分布中的disentangled representation<br>那么如何从latent code中学到相应的disentangled representation呢？ 在原始的GAN中，忽略了c这部分的影响，即GAN产生的数据分布满足$P_{G}(x|C)=P(x)$,为了保证能够利用c这部分信息， 作者提出这样一个假设：c与generator的输出相关程度应该很大，而在信息论中，两个数据分布的相关程度即互信息， 即generator的输出和input的c的$I(c;G(z,c))$应该会大。 所以，InfoGAN就变成如下的优化问题：<br><img src="https://img-blog.csdn.net/20180804191707262?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>因为互信息的计算需要后验概率的分布（下图红线部分），在实际中很难直接使用，因此，在实际训练中一般不会直接最大化$I(c;G(z,c))$<br><img src="https://img-blog.csdn.net/20180804191748702?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>这里作者采用和VAE类似的方法，增加一个辅助的数据分布为后验概率的low bound： 所以，这里互信息的计算如下：<br><img src="https://img-blog.csdn.net/20180804191813177?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>这里相关的证明就不深入了，有兴趣的可以去看看paper。<br>5、实验<br>我写的一版基于TensorFlow的Info-GAN实现：Info-GANburness/tensorflow-101 random的label信息，和对应生成的图像：<br><img src="https://img-blog.csdn.net/2018080419191142?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><img src="https://img-blog.csdn.net/20180804191920586?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>不同random变量控制产生同一class下的不同输出：<br><img src="https://img-blog.csdn.net/20180804191943725?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>6、AC-GAN<br>AC-GAN即auxiliary classifier GAN，对应的paper：[1610.09585] Conditional Image Synthesis With Auxiliary Classifier GANs, 如前面的示意图中所示，AC-GAN的Discriminator中会输出相应的class label的概率，然后更改loss fuction，增加class预测正确的概率， ac-gan是一个tensorflow相关的实现，基于作者自己开发的sugartensor，感觉和paper里面在loss函数的定义上差异，看源码的时候注意下，我这里有参考写了一个基于原生tensorflow的版本AC-GAN.<br>实验<br>各位有兴趣的可以拿代码在其他的数据集上也跑一跑，AC-GAN能够有效利用class label的信息，不仅可以在G时指定需要生成的image的label，同事该class label也能在Discriminator用来扩展loss函数，增加整个对抗网络的性能。 random的label信息，和对应生成的图像：<br><img src="https://img-blog.csdn.net/2018080419203481?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><img src="https://img-blog.csdn.net/20180804192043197?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>不同random变量控制产生同一class下的不同输出：<br><img src="https://img-blog.csdn.net/20180804192102877?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>七、总结<br>照例总结一下，本文中，我基本介绍了下生成式模型方法的各个族系派别，到GAN的基本内容，到InfoGAN、AC-GAN，大部分的工作都来自于阅读相关的paper，自己相关的工作就是 tensorflow下参考sugartensor的内容重现了InfoGAN、AC-GAN的相关内容。<br>当然，本人菜鸟一枚，难免有很多理解不到位的地方，写出来更多的是作为分享，让更多人了解GAN这块的内容，如果任何错误或不合适的地方，敬请在评论中指出，我们一起讨论一起学习 另外我的所有相关的代码都在github上:GAN,相信读一下无论是对TensorFlow的理解还是GAN的理解都会 有一些帮助，简单地参考mnist.py修改下可以很快的应用到你的数据集上，如果有小伙伴在其他数据集上做出有意思的实验效果的，欢迎分享。</li></ul><p>原文地址： <a href="http://www.leiphone.com/news/201702/GZsIbIb9V9AUGmb6.html" target="_blank" rel="noopener">http://www.leiphone.com/news/201702/GZsIbIb9V9AUGmb6.html</a></p>]]></content>
    
    <summary type="html">
    
      该教程前面主要讲解GAN网络的一些概念，后面会基于tensorflow实战，欢迎大家分享学习！
    
    </summary>
    
      <category term="Tensorflow实战深度学习" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Tensorflow%E5%AE%9E%E6%88%98%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Tensorflow" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>基于深度学习tensorflow实现文本分类任务的注意力机制</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/Tensorflow%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8ERNN%E7%9A%84%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/Tensorflow实现基于RNN的文本分类任务的注意力机制/</id>
    <published>2018-08-24T07:23:48.000Z</published>
    <updated>2018-08-24T09:55:23.841Z</updated>
    
    <content type="html"><![CDATA[<p>要点：<br>该教程为深度学习tensorflow实现文本分类任务的注意力机制，实现可视化注意力文本。<br>环境配置：<br>Wn10+CPU i7-6700<br>Pycharm2018<br>Tensorflow 1.8.0<br>Tensorboard 1.8.0<br>笔者信息：Next_Legend  QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络<br>                                                                                                 ——2018.8.8于天津大学</p><hr><p>一、下载代码<br>   该代码见笔者的资源下载部分<a href="https://download.csdn.net/download/jinyuan7708/10592063" target="_blank" rel="noopener">https://download.csdn.net/download/jinyuan7708/10592063</a><br>   代码不需要改动，只需要配置好环境和安装好相应的库，就可以训练和测试了。<br>二、相应的库文件<br>   tensorflow    1.8.0<br>   tensorboard  1.8.0<br>   numpy<br>   keras<br>   tqdm<br>三、工程目录文件<br>  <img src="https://img-blog.csdn.net/20180808222357233?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="工程目录文件"><br>  该项目主要包括attention.py       train.py     utils.py    visualize.py四个文件夹<br>  其中train.py文件是训练模型的文件，运行后会生成model.data-00000-of-00001、model.index、model.meta以及checkpoint文件，也就是训练生成的模型文件。<br>四、核心代码<br><img src="https://img-blog.csdn.net/20180808222935934?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br><img src="https://img-blog.csdn.net/20180808222945807?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br><img src="https://img-blog.csdn.net/20180808222954987?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br><strong>train.py文件代码</strong></p><php><pre><code>from __future__ import print_function, divisionimport numpy as npimport tensorflow as tffrom keras.datasets import imdbfrom tensorflow.contrib.rnn import GRUCellfrom tensorflow.python.ops.rnn import bidirectional_dynamic_rnn as bi_rnnfrom tqdm import tqdmfrom attention import attentionfrom utils import get_vocabulary_size, fit_in_vocabulary, zero_pad, batch_generatorNUM_WORDS = 10000INDEX_FROM = 3SEQUENCE_LENGTH = 250EMBEDDING_DIM = 100HIDDEN_SIZE = 150ATTENTION_SIZE = 50KEEP_PROB = 0.8BATCH_SIZE = 256NUM_EPOCHS = 3  # Model easily overfits without pre-trained words embeddings, that&apos;s why train for a few epochsDELTA = 0.5MODEL_PATH = &apos;./model&apos;# Load the data set(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS, index_from=INDEX_FROM)# Sequences pre-processingvocabulary_size = get_vocabulary_size(X_train)X_test = fit_in_vocabulary(X_test, vocabulary_size)X_train = zero_pad(X_train, SEQUENCE_LENGTH)X_test = zero_pad(X_test, SEQUENCE_LENGTH)# Different placeholderswith tf.name_scope(&apos;Inputs&apos;):batch_ph = tf.placeholder(tf.int32, [None, SEQUENCE_LENGTH], name=&apos;batch_ph&apos;)target_ph = tf.placeholder(tf.float32, [None], name=&apos;target_ph&apos;)seq_len_ph = tf.placeholder(tf.int32, [None], name=&apos;seq_len_ph&apos;)keep_prob_ph = tf.placeholder(tf.float32, name=&apos;keep_prob_ph&apos;)# Embedding layerwith tf.name_scope(&apos;Embedding_layer&apos;):embeddings_var = tf.Variable(tf.random_uniform([vocabulary_size, EMBEDDING_DIM], -1.0, 1.0), trainable=True)tf.summary.histogram(&apos;embeddings_var&apos;, embeddings_var)batch_embedded = tf.nn.embedding_lookup(embeddings_var, batch_ph)# (Bi-)RNN layer(-s)rnn_outputs, _ = bi_rnn(GRUCell(HIDDEN_SIZE), GRUCell(HIDDEN_SIZE),                    inputs=batch_embedded, sequence_length=seq_len_ph, dtype=tf.float32)tf.summary.histogram(&apos;RNN_outputs&apos;, rnn_outputs)# Attention layerwith tf.name_scope(&apos;Attention_layer&apos;):attention_output, alphas = attention(rnn_outputs, ATTENTION_SIZE, return_alphas=True)tf.summary.histogram(&apos;alphas&apos;, alphas)# Dropoutdrop = tf.nn.dropout(attention_output, keep_prob_ph)# Fully connected layerwith tf.name_scope(&apos;Fully_connected_layer&apos;):W = tf.Variable(tf.truncated_normal([HIDDEN_SIZE * 2, 1], stddev=0.1))  # Hidden size is multiplied by 2 for Bi-RNNb = tf.Variable(tf.constant(0., shape=[1]))y_hat = tf.nn.xw_plus_b(drop, W, b)y_hat = tf.squeeze(y_hat)tf.summary.histogram(&apos;W&apos;, W)with tf.name_scope(&apos;Metrics&apos;):    # Cross-entropy loss and optimizer initialization    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_hat, labels=target_ph))    tf.summary.scalar(&apos;loss&apos;, loss) optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)# Accuracy metricaccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(tf.sigmoid(y_hat)), target_ph), tf.float32))tf.summary.scalar(&apos;accuracy&apos;, accuracy)merged = tf.summary.merge_all()train_batch_generator = batch_generator(X_train, y_train, BATCH_SIZE)test_batch_generator = batch_generator(X_test, y_test, BATCH_SIZE)train_writer = tf.summary.FileWriter(&apos;./logdir/train&apos;, accuracy.graph)test_writer = tf.summary.FileWriter(&apos;./logdir/test&apos;, accuracy.graph)session_conf = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))saver = tf.train.Saver()if __name__ == &quot;__main__&quot;:with tf.Session(config=session_conf) as sess:    sess.run(tf.global_variables_initializer())    print(&quot;Start learning...&quot;)    for epoch in range(NUM_EPOCHS):        loss_train = 0        loss_test = 0        accuracy_train = 0        accuracy_test = 0        print(&quot;epoch: {}\t&quot;.format(epoch), end=&quot;&quot;)        # Training        num_batches = X_train.shape[0] // BATCH_SIZE        for b in tqdm(range(num_batches)):            x_batch, y_batch = next(train_batch_generator)            seq_len = np.array([list(x).index(0) + 1 for x in x_batch])  # actual lengths of sequences            loss_tr, acc, _, summary = sess.run([loss, accuracy, optimizer, merged],                                                feed_dict={batch_ph: x_batch,                                                           target_ph: y_batch,                                                           seq_len_ph: seq_len,                                                           keep_prob_ph: KEEP_PROB})            accuracy_train += acc            loss_train = loss_tr * DELTA + loss_train * (1 - DELTA)            train_writer.add_summary(summary, b + num_batches * epoch)        accuracy_train /= num_batches        # Testing        num_batches = X_test.shape[0] // BATCH_SIZE        for b in tqdm(range(num_batches)):            x_batch, y_batch = next(test_batch_generator)            seq_len = np.array([list(x).index(0) + 1 for x in x_batch])  # actual lengths of sequences            loss_test_batch, acc, summary = sess.run([loss, accuracy, merged],                                                     feed_dict={batch_ph: x_batch,                                                                target_ph: y_batch,                                                                seq_len_ph: seq_len,                                                                keep_prob_ph: 1.0})            accuracy_test += acc            loss_test += loss_test_batch            test_writer.add_summary(summary, b + num_batches * epoch)        accuracy_test /= num_batches        loss_test /= num_batches        print(&quot;loss: {:.3f}, val_loss: {:.3f}, acc: {:.3f}, val_acc: {:.3f}&quot;.format(            loss_train, loss_test, accuracy_train, accuracy_test        ))    train_writer.close()    test_writer.close()    saver.save(sess, MODEL_PATH)    print(&quot;Run &apos;tensorboard --logdir=./logdir&apos; to checkout tensorboard logs.&quot;)</code></pre><p></p></php><br>五、训练过程<br>   <img src="https://img-blog.csdn.net/20180808224427275?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>   笔者由于使用的 CPU来进行训练，所以速度比较慢，感兴趣的朋友可以考虑使用GPU来计算，可以大大减少训练模型的时间。如果不会搭建gpu环境的小伙伴可以参考我的另一篇Tensorflow gpu环境搭建 ，附上地址哈：<br>   <a href="https://blog.csdn.net/jinyuan7708/article/details/79642924" target="_blank" rel="noopener">https://blog.csdn.net/jinyuan7708/article/details/79642924</a><br>六、训练结果<br>  <img src="https://img-blog.csdn.net/20180808224902778?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="训练生成的model文件"><br>七、Tensorboard可视化<br><img src="https://img-blog.csdn.net/20180808225017120?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="accuracy"><br><img src="https://img-blog.csdn.net/20180808225026854?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="loss"><br><img src="https://img-blog.csdn.net/20180808225040674?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="计算图"><br>八、visualization可视化结果<br>得到模型后，再继续执行visualize.py文件，生成结果可视化。如下图：<br><img src="https://img-blog.csdn.net/20180808225248673?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>至此，我们的教程就结束啦，代码等文件我上传到我的blog下载资源部分，欢迎大家下载批评指正哈!<br>代码地址：<a href="https://download.csdn.net/download/jinyuan7708/10592063" target="_blank" rel="noopener">https://download.csdn.net/download/jinyuan7708/10592063</a><p></p>]]></content>
    
    <summary type="html">
    
      该教程为深度学习tensorflow实现文本分类任务的注意力机制，实现可视化注意力文本。
    
    </summary>
    
      <category term="Tensorflow实战深度学习" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Tensorflow%E5%AE%9E%E6%88%98%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Tensorflow" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>中英文NLP集成型工具汇总</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/%E4%B8%AD%E8%8B%B1%E6%96%87NLP%E9%9B%86%E6%88%90%E5%9E%8B%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/中英文NLP集成型工具汇总/</id>
    <published>2018-08-24T07:22:48.000Z</published>
    <updated>2018-08-24T09:56:08.365Z</updated>
    
    <content type="html"><![CDATA[<p><strong>该文档简单总结了一下集成的中英文NLP工具，分享给NLP领域的大家！</strong><br>笔者信息：Next_Legend QQ:1219154092 机器学习 自然语言处理 计算机视觉 深度学习<br>——2018.8.19于天津大学</p><hr><p><strong>1、面向研究的StanfordNLP(Java) (CoreNLP/Parder/POS Tager/NER…) <a href="https://nlp.stanford.edu/software/index.shtml" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819205836357?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>2、面向应用的SpaCy(Python) <a href="https://spacy.io/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819205650448?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>3、哈工大语言技术平台LTP(C++) <a href="https://github.com/HIT-SCIR/ltp" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819205956673?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>4、本土的HanLP(Java) <a href="http://hanlp.hankcs.com/?sentence=%E6%88%91%E7%88%B1%E4%BD%A0%E4%B8%AD%E5%9B%BD%EF%BC%8C%E6%88%91%E5%9C%A8%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%EF%BC%8C%E6%88%91%E7%88%B1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%82" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/2018081921031468?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>5、轻量非主流的xmnlp(Python) <a href="https://github.com/SeanLee97/xmnlp" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819210436793?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>6、相对零散的THUNLP开放项目 <a href="https://github.com/thunlp" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819210536217?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>7、复旦大学NLP <a href="http://nlp.fudan.edu.cn/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819210840388?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>8、清华大学NLP <a href="http://thulac.thunlp.org/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819211018822?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>9、TEXTBLOG <a href="https://textblob.readthedocs.io/en/dev/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819211200578?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>10、PyNLPIR <a href="https://pypi.org/project/PyNLPIR/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819211324571?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>11、Polyglot <a href="https://polyglotclub.com/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/2018081921152564?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>12、NLTK <a href="http://www.nltk.org/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819211652437?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>其他的NLP工具小编暂时没有了解，欢迎有使用经验的同学朋友补充！ </strong></p>]]></content>
    
    <summary type="html">
    
      该文档简单总结了一下集成的中英文NLP工具，分享给NLP领域的大家！
    
    </summary>
    
      <category term="NLP" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/NLP/"/>
    
    
      <category term="自然语言处理" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>算法_NLP_深度学习_机器学习面试笔记</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/%E7%AE%97%E6%B3%95_NLP_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/算法_NLP_深度学习_机器学习面试笔记/</id>
    <published>2018-08-24T07:20:48.000Z</published>
    <updated>2018-08-24T09:55:46.446Z</updated>
    
    <content type="html"><![CDATA[<p>笔者信息：Next_Legend QQ:1219154092 机器学习 自然语言处理 图像处理 深度学习<br>——2018.8.13于天津大学</p><hr><div class="article_content clearfix csdn-tracking-statistics" id="article_content" data-mod="popu_307" data-dsm="post" data-pid="blog"><br>                    <div class="markdown_views"><br>                <p><strong>GitHub 地址</strong>：<a href="https://github.com/imhuay/CS_Interview_Notes-Chinese" target="_blank" rel="nofollow">https://github.com/imhuay/CS_Interview_Notes-Chinese</a></p><br><br><p>深度学习/机器学习面试问题整理，想法来源于这个<a href="https://github.com/elviswf/DeepLearningBookQA_cn" target="_blank" rel="nofollow">仓库</a>. <br><br>- 该仓库整理了“花书”《深度学习》中的一些常见问题，其中部分偏理论的问题没有收录，如有需要可以浏览原仓库。</p><br><br><p>此外，还包括我看到的所有机器学习/深度学习面经中的问题。除了其中 DL/ML 相关的，其他与算法岗相关的计算机知识也会记录。</p><br><br><p>但是不会包括如前端/测试/JAVA/Android等岗位中有关的问题。</p><br><br><br><br><h2 id="roadmap"><a name="t0"></a>RoadMap</h2><br><br><ul><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/数学" target="_blank" rel="nofollow">数学</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/数学/微积分的本质.md" target="_blank" rel="nofollow">微积分的本质</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/数学/深度学习的核心.md" target="_blank" rel="nofollow">深度学习的核心</a></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理" target="_blank" rel="nofollow">自然语言处理</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-词向量.md" target="_blank" rel="nofollow">词向量</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-词向量.md#word2vec" target="_blank" rel="nofollow">Word2Vec</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-词向量.md#glove" target="_blank" rel="nofollow">GloVe</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-词向量.md#fasttext" target="_blank" rel="nofollow">FastText</a></li><br><li>WordRank TODO</li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-序列建模.md" target="_blank" rel="nofollow">序列建模</a> TODO</li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-工具库.md" target="_blank" rel="nofollow">工具库</a></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习" target="_blank" rel="nofollow">机器学习-深度学习</a> <br><br><ul><li>公共基础 <br><br><ul><li>背景知识</li><br><li>损失函数</li></ul></li><br><li>深度学习 <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习/DL专题-深度学习基础.md" target="_blank" rel="nofollow">深度学习基础</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习/DL专题-《深度学习》整理.md" target="_blank" rel="nofollow">《深度学习》整理</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习/DL专题-CNN.md" target="_blank" rel="nofollow">CNN专题</a></li></ul></li><br><li>机器学习 <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习/ML专题-机器学习算法.md" target="_blank" rel="nofollow">机器学习算法</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习/ML专题-机器学习实践.md" target="_blank" rel="nofollow">机器学习实践</a></li></ul></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/算法" target="_blank" rel="nofollow">算法</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/算法/题解-剑指Offer.md" target="_blank" rel="nofollow">题解-剑指Offer</a></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/编程语言" target="_blank" rel="nofollow">编程语言</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/编程语言/Cpp专题-基础知识.md" target="_blank" rel="nofollow">Cpp专题-基础知识</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/编程语言/Cpp专题-左值与右值.md" target="_blank" rel="nofollow">Cpp专题-左值与右值</a></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/笔试面经" target="_blank" rel="nofollow">笔试面经</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/项目经验" target="_blank" rel="nofollow">项目经验</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/code" target="_blank" rel="nofollow">code</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/code/工具库" target="_blank" rel="nofollow">工具库</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/code/工具库/gensim/FastText.py" target="_blank" rel="nofollow">gensim.FastText 的使用</a></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/code/倒排索引" target="_blank" rel="nofollow">倒排索引</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/code/tf-基础" target="_blank" rel="nofollow">Tensorflow 基础</a> TODO</li></ul></li><br><li>各公司<a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/招聘要求.md" target="_blank" rel="nofollow">招聘要求</a></li><br></ul><br><br><h2 id="必备清单-todo"><a name="t1"></a>必备清单 TODO</h2><br><br><ul><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/深度学习/README.md" target="_blank" rel="nofollow">深度学习</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/深度学习/README.md#反向传播算法" target="_blank" rel="nofollow">反向传播算法</a></li><br><li><a href="#梯度下降法" target="_self" rel="nofollow">梯度下降法</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/项目经验/README.md" target="_blank" rel="nofollow">深度学习实践</a>（项目经验）</li><br><li>相关代码 TODO</li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习/README.md" target="_blank" rel="nofollow">机器学习算法</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习/README.md#逻辑斯蒂回归" target="_blank" rel="nofollow">逻辑斯蒂回归</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习/README.md#支持向量机" target="_blank" rel="nofollow">支持向量机</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习/README.md#adaboost-算法" target="_blank" rel="nofollow">AdaBoost 算法</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习/README.md#梯度提升决策树-gbdt" target="_blank" rel="nofollow">GBDT 梯度提升决策树</a></li><br><li>相关代码 TODO</li></ul></li><br><li>计算机基础 <br><br><ul><li><a href="https://github.com/imhuay/Algorithm_for_Interview-Chinese/tree/master/Algorithm_for_Interview/_必背算法" target="_blank" rel="nofollow">必背算法</a></li><br><li>Python 常识 TODO</li><br><li>C++ 常识 TODO</li></ul></li><br></ul><br><br><br><br><h2 id="欢迎分享你在深度学习机器学习面试过程中遇见的问题"><a name="t2"></a><strong>欢迎分享你在深度学习/机器学习面试过程中遇见的问题！</strong></h2><br><br><p>你可以直接以你遇到的问题作为 issue 标题，然后分享你的回答或者其他参考资料。</p><br><br><p>当然，你也可以直接创建 PR，分享问题的同时改正我的错误！</p><br><br><blockquote><br>  <p>我会经常修改文档的结构（特别是代码的链接）。如果文中有链接失效，请告诉我！ <br><br>  文档中大部分链接都是指向仓库内的文件或标记；涉及编程代码的链接会指向我的另一个仓库（<a href="https://github.com/imhuay/Algorithm_for_Interview-Chinese" target="_blank" rel="nofollow">Algorithm_for_Interview</a>）</p><br></blockquote><br><br><br><br><h3 id="reference"><a name="t3"></a>Reference</h3><br><br><ul><br><li>exacity/<a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="nofollow">deeplearningbook-chinese</a>: 深度学习中文版 </li><br><li>elviswf/<a href="https://github.com/elviswf/DeepLearningBookQA_cn" target="_blank" rel="nofollow">DeepLearningBookQA_cn</a>: 深度学习面试问题 回答对应的DeepLearning中文版页码</li><br><li>huihut/<a href="https://github.com/huihut/interview" target="_blank" rel="nofollow">interview: C/C++面试知识总结</a> </li><br><li>七月在线：<a href="https://blog.csdn.net/v_july_v" target="_blank" rel="nofollow">结构之法 算法之道</a> - CSDN博客</li><br><li>在线 LaTeX 公式编辑器 <a href="http://www.codecogs.com/latex/eqneditor.php" target="_blank" rel="nofollow">http://www.codecogs.com/latex/eqneditor.php</a></li><br><li>GitHub 搜索：<a href="https://github.com/search?q=deep+learning+interview" target="_blank" rel="nofollow">Deep Learning Interview</a></li><br><li>GitHub 搜索：<a href="https://github.com/search?q=machine+learning+interview" target="_blank" rel="nofollow">Machine Learning Interview</a> <br><br><ul><li>geekcircle/<a href="https://github.com/geekcircle/machine-learning-interview-qa" target="_blank" rel="nofollow">machine-learning-interview-qa</a>: 人工智能-机器学习笔试面试题解析 </li></ul></li><br><li><a href="https://www.nowcoder.com/discuss?type=2&amp;order=0" target="_blank" rel="nofollow">牛客网-讨论区</a></li><br></ul>            </div><br>            <link href="https://csdnimg.cn/release/phoenix/template/css/markdown_views-ea0013b516.css" rel="stylesheet"><br>                </div>]]></content>
    
    <summary type="html">
    
      该集锦是2018年机器学习以及深度学习算法岗位笔记汇总，欢迎大家学习交流！
    
    </summary>
    
      <category term="面试集锦" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E9%9D%A2%E8%AF%95%E9%9B%86%E9%94%A6/"/>
    
    
      <category term="算法" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>基于python+opencv的图像目标区域自动提取</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/%E5%9F%BA%E4%BA%8Epython+opencv%E7%9A%84%E5%9B%BE%E5%83%8F%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E8%87%AA%E5%8A%A8%E6%8F%90%E5%8F%96%EF%BC%88%E6%9C%AC%E9%A1%B9%E7%9B%AE%E4%B8%BA%E6%8F%90%E5%8F%96%E7%BA%B8%E5%BC%A0%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%89/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/基于python+opencv的图像目标区域自动提取（本项目为提取纸张中的内容）/</id>
    <published>2018-08-24T07:17:48.000Z</published>
    <updated>2018-08-24T07:18:06.447Z</updated>
    
    <content type="html"><![CDATA[<p>要点：<br>该教程为基于python+opencv的图像目标区域自动提取，实现自动提取一张照片中的纸张内容<br>环境配置：<br>Wn10+CPU i7-6700<br>Pycharm2018<br>opencv-python 3.4.2.17<br>numpy 1.14.5<br>笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络<br>                                                ——2018.8.12于天津大学</p><p>该项目的代码在笔者的资源仓库中，代码地址：<br><a href="https://download.csdn.net/download/jinyuan7708/10599212" target="_blank" rel="noopener">基于python+opencv的图像目标区域自动提取</a></p><hr><p>一、项目背景<br>一张照片中的感兴趣区域总是沿着x,y,z三个轴都有一定倾斜（如下图），要想把照片翻转到平行位置，需要进行透视变换，而透视变换需要同一像素点变换前后的坐标。由此可以想到，提取矩形区域四个角的坐标作为变换前的坐标，变换后的坐标可以设为照片的四个角落，经过投影变换，矩形区域将会翻转并充满图像。<br><strong>因此我们要解决的问题变为：提取矩形的四个角落、进行透视变换。</strong><img src="https://img-blog.csdn.net/20180812200443662?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><p>二、提取矩形角落坐标<br>矩形的检测主要是提取边缘，图片显示部分的亮度通常高于周围环境，我们可以将图片阈值化，将图片部分与周围环境明显的分别开来，这对后边的边缘检测非常有帮助。<br><strong>检测矩形并提取坐标需要对图像进行预处理、边缘检测、提取轮廓、检测凸包、角点检测。</strong><br>1、预处理转为灰度图<br>由于手机拍摄的照片像素可能会很高，为了加快处理速度，我们首先将图像转化为灰度图<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">image</span> = cv2.imread(Config.src)</span><br><span class="line">gray = cv2.cvtColor(<span class="built_in">image</span>, cv2.COLOR_BGR2GRAY)</span><br><span class="line">srcWidth, srcHeight, channels = <span class="built_in">image</span>.<span class="built_in">shape</span></span><br><span class="line"><span class="built_in">print</span>(srcWidth, srcHeight)</span><br></pre></td></tr></table></figure></p><p>2、中值滤波</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">binary</span> = cv2.medianBlur(gray,<span class="number">7</span>)</span><br></pre></td></tr></table></figure><p>3、转化为二值图像<br><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ret, <span class="built_in">binary</span> = cv2.threshold(<span class="built_in">binary</span>, Config.threshold_thresh, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line">cv2.imwrite(<span class="string">"1-threshold.png"</span>, <span class="built_in">binary</span>, [<span class="built_in">int</span>(cv2.IMWRITE_PNG_COMPRESSION), <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p><p>此时图片已经变成了这个样子：<br><img src="https://img-blog.csdn.net/20180812194831910?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>可见纸张页面部分已经与背景环境分离开来。<br>4、边缘检测与轮廓处理<br>我们用Canny算子边缘检测，提取轮廓</p><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># canny提取轮廓</span></span><br><span class="line"><span class="built_in">binary</span> = cv2.Canny(<span class="built_in">binary</span>, <span class="number">0</span>, <span class="number">60</span>, apertureSize = <span class="number">3</span>)</span><br><span class="line">cv2.imwrite(<span class="string">"3-canny.png"</span>, <span class="built_in">binary</span>, [<span class="built_in">int</span>(cv2.IMWRITE_PNG_COMPRESSION), <span class="number">9</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdn.net/20180812195304944?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>提取轮廓后，拟合外接多边形（矩形）</strong></p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 提取轮廓后，拟合外接多边形（矩形）</span></span><br><span class="line"><span class="literal">_</span>,contours,<span class="literal">_</span> = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">print(<span class="string">"len(contours)=%d"</span>%(len(contours)))</span><br></pre></td></tr></table></figure><p>5、提取面积最大的轮廓并用多边形将轮廓包围</p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> idx,c in enumerate(contours):</span><br><span class="line">    <span class="keyword">if</span> len(c) &lt; Config.min_contours:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    epsilon = Config.epsilon_start</span><br><span class="line">    <span class="keyword">while</span> True:</span><br><span class="line">        approx = cv2.approxPolyDP(c,epsilon,True)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"idx,epsilon,len(approx),len(c)=%d,%d,%d,%d"</span>%(idx,epsilon,len(approx),len(c)))</span><br><span class="line">        <span class="keyword">if</span> (len(approx) &lt; <span class="number">4</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> math.fabs(cv2.contourArea(approx)) &gt; Config.min_area:</span><br><span class="line">            <span class="keyword">if</span> (len(approx) &gt; <span class="number">4</span>):</span><br><span class="line">                epsilon += Config.epsilon_step</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">"epsilon=%d, count=%d"</span>%(epsilon,len(approx)))</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                #<span class="keyword">for</span> p in approx:</span><br><span class="line">                #    cv2.circle(<span class="built_in">binary</span>,(p[<span class="number">0</span>][<span class="number">0</span>],p[<span class="number">0</span>][<span class="number">1</span>]),<span class="number">8</span>,(<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>),thickness=<span class="number">-1</span>)</span><br><span class="line">                approx = approx.reshape((<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line">                # 点重排序, [top-left, top-right, bottom-right, bottom-left]</span><br><span class="line">                src_rect = order_points(approx)</span><br><span class="line"></span><br><span class="line">                cv2.drawContours(<span class="built_in">image</span>, c, <span class="number">-1</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>),<span class="number">1</span>)</span><br><span class="line">                cv2.<span class="built_in">line</span>(<span class="built_in">image</span>, (src_rect[<span class="number">0</span>][<span class="number">0</span>],src_rect[<span class="number">0</span>][<span class="number">1</span>]),(src_rect[<span class="number">1</span>][<span class="number">0</span>],src_rect[<span class="number">1</span>][<span class="number">1</span>]),<span class="built_in">color</span>=(<span class="number">100</span>,<span class="number">255</span>,<span class="number">100</span>))</span><br><span class="line">                cv2.<span class="built_in">line</span>(<span class="built_in">image</span>, (src_rect[<span class="number">2</span>][<span class="number">0</span>],src_rect[<span class="number">2</span>][<span class="number">1</span>]),(src_rect[<span class="number">1</span>][<span class="number">0</span>],src_rect[<span class="number">1</span>][<span class="number">1</span>]),<span class="built_in">color</span>=(<span class="number">100</span>,<span class="number">255</span>,<span class="number">100</span>))</span><br><span class="line">                cv2.<span class="built_in">line</span>(<span class="built_in">image</span>, (src_rect[<span class="number">2</span>][<span class="number">0</span>],src_rect[<span class="number">2</span>][<span class="number">1</span>]),(src_rect[<span class="number">3</span>][<span class="number">0</span>],src_rect[<span class="number">3</span>][<span class="number">1</span>]),<span class="built_in">color</span>=(<span class="number">100</span>,<span class="number">255</span>,<span class="number">100</span>))</span><br><span class="line">                cv2.<span class="built_in">line</span>(<span class="built_in">image</span>, (src_rect[<span class="number">0</span>][<span class="number">0</span>],src_rect[<span class="number">0</span>][<span class="number">1</span>]),(src_rect[<span class="number">3</span>][<span class="number">0</span>],src_rect[<span class="number">3</span>][<span class="number">1</span>]),<span class="built_in">color</span>=(<span class="number">100</span>,<span class="number">255</span>,<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">                # 获取最小矩形包络</span><br><span class="line">                <span class="built_in">rect</span> = cv2.minAreaRect(approx)</span><br><span class="line">                # <span class="built_in">rect</span> = cv2.maxAreaRect(approx)</span><br><span class="line">                <span class="built_in">box</span> = cv2.boxPoints(<span class="built_in">rect</span>)</span><br><span class="line">                <span class="built_in">box</span> = np.int0(<span class="built_in">box</span>)</span><br><span class="line">                <span class="built_in">box</span> = <span class="built_in">box</span>.reshape(<span class="number">4</span>,<span class="number">2</span>)</span><br><span class="line">                <span class="built_in">box</span> = order_points(<span class="built_in">box</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">"approx-&gt;box"</span>)</span><br><span class="line">                <span class="built_in">print</span>(approx)</span><br><span class="line">                <span class="built_in">print</span>(src_rect)</span><br><span class="line">                <span class="built_in">print</span>(<span class="built_in">box</span>)</span><br><span class="line">                w,h = point_distance(<span class="built_in">box</span>[<span class="number">0</span>],<span class="built_in">box</span>[<span class="number">1</span>]), \</span><br><span class="line">                      point_distance(<span class="built_in">box</span>[<span class="number">1</span>],<span class="built_in">box</span>[<span class="number">2</span>])</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">"w,h=%d,%d"</span>%(w,h))</span><br></pre></td></tr></table></figure><p>6、 透视变换</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dst_rect = np.array([</span><br><span class="line">                    [<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [w - <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                    [w - <span class="number">1</span>, h - <span class="number">1</span>],</span><br><span class="line">                    [<span class="number">0</span>, h - <span class="number">1</span>]],</span><br><span class="line">                    dtype=<span class="string">"float32"</span>)</span><br><span class="line">                M = cv2.getPerspectiveTransform(src_rect, dst_rect)</span><br><span class="line">                warped = cv2.warpPerspective(image, M, (w, h))</span><br><span class="line">                cv2.imwrite(<span class="string">"transfer%d.png"</span>%idx, warped, [int(cv2.IMWRITE_PNG_COMPRESSION), <span class="number">9</span>])</span><br><span class="line">                break</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdn.net/20180812195725900?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>总结<br>本项目利用了照片背景亮度较高的特点，通过二值化突出轮廓提取坐标，进行透视变换。但是局限性在于，如果矩形的亮度与背景相差不大，就很难用这种方法检测到轮廓还需要算法优化。该项目的代码在笔者的资源仓库中，代码地址：<br><a href="https://download.csdn.net/download/jinyuan7708/10599212" target="_blank" rel="noopener">基于python+opencv的图像目标区域自动提取</a></p>]]></content>
    
    <summary type="html">
    
      该教程为基于python+opencv的图像目标区域自动提取，实现自动提取一张照片中的纸张内容
    
    </summary>
    
      <category term="计算机视觉" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
  </entry>
  
  <entry>
    <title>基于Kears的Attention实战</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/%E5%9F%BA%E4%BA%8EKeras%E7%9A%84attention%E5%AE%9E%E6%88%98/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/基于Keras的attention实战/</id>
    <published>2018-08-24T03:34:48.000Z</published>
    <updated>2018-08-24T03:34:13.116Z</updated>
    
    <content type="html"><![CDATA[<p>要点：<br>该教程为基于Kears的Attention实战，环境配置：<br>Wn10+CPU i7-6700<br>Pycharm 2018<br>python 3.6<br>numpy 1.14.5<br>Keras 2.0.2<br>Matplotlib 2.2.2<br><strong><em>强调：各种库的版本型号一定要配置对，因为Keras以及Tensorflow升级更新比较频繁，很多函数更新后要么更换了名字，要么没有这个函数了，所以大家务必重视。</em></strong><br><strong>相关代码我放在了我的代码仓库里哈，欢迎大家下载，这里附上地址：<a href="https://download.csdn.net/download/jinyuan7708/10617858" target="_blank" rel="noopener">基于Kears的Attention实战</a></strong><br>笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络<br>——2018.8.21于天津大学</p><hr><p>一、导读<br>最近两年，尤其在今年，注意力机制(Attention)及其变种Attention逐渐热了起来，在很多顶会Paper中都或多或少的用到了attention,所以小编出于好奇，整理了这篇基于Kears的Attention实战，本教程仅从代码的角度来看Attention。通过一个简单的例子，探索Attention机制是如何在模型中起到特征选择作用的。<br>二、代码实战（一）<br>1、导入相关库文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> attention_utils <span class="keyword">import</span> get_activations, get_data</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1337</span>)  <span class="comment"># for reproducibility</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense, merge</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure></p><p>2、数据生成函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(n, input_dim, attention_column=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Data generation. x is purely random except that it's first value equals the target y.</span></span><br><span class="line"><span class="string">    In practice, the network should learn that the target = x[attention_column].</span></span><br><span class="line"><span class="string">    Therefore, most of its attention should be focused on the value addressed by attention_column.</span></span><br><span class="line"><span class="string">    :param n: the number of samples to retrieve.</span></span><br><span class="line"><span class="string">    :param input_dim: the number of dimensions of each element in the series.</span></span><br><span class="line"><span class="string">    :param attention_column: the column linked to the target. Everything else is purely random.</span></span><br><span class="line"><span class="string">    :return: x: model inputs, y: model targets</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    x = np.random.standard_normal(size=(n, input_dim))</span><br><span class="line">    y = np.random.randint(low=<span class="number">0</span>, high=<span class="number">2</span>, size=(n, <span class="number">1</span>))</span><br><span class="line">    x[:, attention_column] = y[:, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure><p>3、模型定义函数<br>将输入进行一次变换后，计算出Attention权重，将输入乘上Attention权重，获得新的特征。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">()</span>:</span></span><br><span class="line">    inputs = Input(shape=(input_dim,))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ATTENTION PART STARTS HERE</span></span><br><span class="line">    attention_probs = Dense(input_dim, activation=<span class="string">'softmax'</span>, name=<span class="string">'attention_vec'</span>)(inputs)</span><br><span class="line">    attention_mul =merge([inputs, attention_probs], output_shape=<span class="number">32</span>, name=<span class="string">'attention_mul'</span>, mode=<span class="string">'mul'</span>)</span><br><span class="line">    <span class="comment"># ATTENTION PART FINISHES HERE</span></span><br><span class="line"></span><br><span class="line">    attention_mul = Dense(<span class="number">64</span>)(attention_mul)</span><br><span class="line">    output = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(attention_mul)</span><br><span class="line">    model = Model(input=[inputs], output=output)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p><p>4、主函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    N = <span class="number">10000</span></span><br><span class="line">    inputs_1, outputs = get_data(N, input_dim)</span><br><span class="line"></span><br><span class="line">    m = build_model()</span><br><span class="line">    m.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">    print(m.summary())</span><br><span class="line"></span><br><span class="line">    m.fit([inputs_1], outputs, epochs=<span class="number">20</span>, batch_size=<span class="number">64</span>, validation_split=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    testing_inputs_1, testing_outputs = get_data(<span class="number">1</span>, input_dim)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Attention vector corresponds to the second matrix.</span></span><br><span class="line">    <span class="comment"># The first one is the Inputs output.</span></span><br><span class="line">    attention_vector = get_activations(m, testing_inputs_1,</span><br><span class="line">                                       print_shape_only=<span class="keyword">True</span>,</span><br><span class="line">                                       layer_name=<span class="string">'attention_vec'</span>)[<span class="number">0</span>].flatten()</span><br><span class="line">    print(<span class="string">'attention ='</span>, attention_vector)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot part.</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">    pd.DataFrame(attention_vector, columns=[<span class="string">'attention (%)'</span>]).plot(kind=<span class="string">'bar'</span>,</span><br><span class="line">                                                                   title=<span class="string">'Attention Mechanism as '</span></span><br><span class="line">                                                                         <span class="string">'a function of input'</span></span><br><span class="line">                                                                         <span class="string">' dimensions.'</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p><p>5、运行结果<br>代码中，attention_column为1，也就是说，label只与数据的第1个特征相关。从运行结果中可以看出，Attention权重成功地获取了这个信息。<br><img src="https://img-blog.csdn.net/20180821160600590?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><hr><p>三、代码实战（二）<br>1、导入相关库文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> merge</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.layers.recurrent <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> attention_utils <span class="keyword">import</span> get_activations, get_data_recurrent</span><br><span class="line">INPUT_DIM = <span class="number">2</span></span><br><span class="line">TIME_STEPS = <span class="number">20</span></span><br><span class="line"><span class="comment"># if True, the attention vector is shared across the input_dimensions where the attention is applied.</span></span><br><span class="line">SINGLE_ATTENTION_VECTOR = <span class="keyword">False</span></span><br><span class="line">APPLY_ATTENTION_BEFORE_LSTM = <span class="keyword">False</span></span><br></pre></td></tr></table></figure></p><p>2、数据生成函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention_3d_block</span><span class="params">(inputs)</span>:</span></span><br><span class="line">    <span class="comment"># inputs.shape = (batch_size, time_steps, input_dim)</span></span><br><span class="line">    input_dim = int(inputs.shape[<span class="number">2</span>])</span><br><span class="line">    a = Permute((<span class="number">2</span>, <span class="number">1</span>))(inputs)</span><br><span class="line">    a = Reshape((input_dim, TIME_STEPS))(a) <span class="comment"># this line is not useful. It's just to know which dimension is what.</span></span><br><span class="line">    a = Dense(TIME_STEPS, activation=<span class="string">'softmax'</span>)(a)</span><br><span class="line">    <span class="keyword">if</span> SINGLE_ATTENTION_VECTOR:</span><br><span class="line">        a = Lambda(<span class="keyword">lambda</span> x: K.mean(x, axis=<span class="number">1</span>), name=<span class="string">'dim_reduction'</span>)(a)</span><br><span class="line">        a = RepeatVector(input_dim)(a)</span><br><span class="line">    a_probs = Permute((<span class="number">2</span>, <span class="number">1</span>), name=<span class="string">'attention_vec'</span>)(a)</span><br><span class="line">    output_attention_mul = merge([inputs, a_probs], name=<span class="string">'attention_mul'</span>, mode=<span class="string">'mul'</span>)</span><br><span class="line">    <span class="keyword">return</span> output_attention_mul</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_attention_applied_after_lstm</span><span class="params">()</span>:</span></span><br><span class="line">    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))</span><br><span class="line">    lstm_units = <span class="number">32</span></span><br><span class="line">    lstm_out = LSTM(lstm_units, return_sequences=<span class="keyword">True</span>)(inputs)</span><br><span class="line">    attention_mul = attention_3d_block(lstm_out)</span><br><span class="line">    attention_mul = Flatten()(attention_mul)</span><br><span class="line">    output = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(attention_mul)</span><br><span class="line">    model = Model(input=[inputs], output=output)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_attention_applied_before_lstm</span><span class="params">()</span>:</span></span><br><span class="line">    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))</span><br><span class="line">    attention_mul = attention_3d_block(inputs)</span><br><span class="line">    lstm_units = <span class="number">32</span></span><br><span class="line">    attention_mul = LSTM(lstm_units, return_sequences=<span class="keyword">False</span>)(attention_mul)</span><br><span class="line">    output = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(attention_mul)</span><br><span class="line">    model = Model(input=[inputs], output=output)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>3、主函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">   N = <span class="number">300000</span></span><br><span class="line">   <span class="comment"># N = 300 -&gt; too few = no training</span></span><br><span class="line">   inputs_1, outputs = get_data_recurrent(N, TIME_STEPS, INPUT_DIM)</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> APPLY_ATTENTION_BEFORE_LSTM:</span><br><span class="line">       m = model_attention_applied_before_lstm()</span><br><span class="line">   <span class="keyword">else</span>:</span><br><span class="line">       m = model_attention_applied_after_lstm()</span><br><span class="line"></span><br><span class="line">   m.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">   print(m.summary())</span><br><span class="line"></span><br><span class="line">   m.fit([inputs_1], outputs, epochs=<span class="number">1</span>, batch_size=<span class="number">64</span>, validation_split=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">   attention_vectors = []</span><br><span class="line">   <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">300</span>):</span><br><span class="line">       testing_inputs_1, testing_outputs = get_data_recurrent(<span class="number">1</span>, TIME_STEPS, INPUT_DIM)</span><br><span class="line">       attention_vector = np.mean(get_activations(m,</span><br><span class="line">                                                  testing_inputs_1,</span><br><span class="line">                                                  print_shape_only=<span class="keyword">True</span>,</span><br><span class="line">                                                  layer_name=<span class="string">'attention_vec'</span>)[<span class="number">0</span>], axis=<span class="number">2</span>).squeeze()</span><br><span class="line">       print(<span class="string">'attention ='</span>, attention_vector)</span><br><span class="line">       <span class="keyword">assert</span> (np.sum(attention_vector) - <span class="number">1.0</span>) &lt; <span class="number">1e-5</span></span><br><span class="line">       attention_vectors.append(attention_vector)</span><br><span class="line"></span><br><span class="line">   attention_vector_final = np.mean(np.array(attention_vectors), axis=<span class="number">0</span>)</span><br><span class="line">   <span class="comment"># plot part.</span></span><br><span class="line">   <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">   <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">   pd.DataFrame(attention_vector_final, columns=[<span class="string">'attention (%)'</span>]).plot(kind=<span class="string">'bar'</span>,</span><br><span class="line">                                                                        title=<span class="string">'Attention Mechanism as '</span></span><br><span class="line">                                                                              <span class="string">'a function of input'</span></span><br><span class="line">                                                                              <span class="string">' dimensions.'</span>)</span><br><span class="line">   plt.show()</span><br></pre></td></tr></table></figure></p><p>4、运行结果<br>代码中，attention_column为10，11，也就是说，label只与数据的第10，11个特征相关。从运行结果中可以看出，Attention权重成功地获取了这个信息。<br><img src="https://img-blog.csdn.net/20180821160943644?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><p>##<strong>相关代码放在代码仓库里哈，欢迎大家下载，这里附上地址：<a href="https://download.csdn.net/download/jinyuan7708/10617858" target="_blank" rel="noopener">基于Kears的Attention实战</a></strong></p>]]></content>
    
    <summary type="html">
    
      该教程是基于Kears的Attention实战
    
    </summary>
    
      <category term="深度学习" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>new Types</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/new-Types/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/new-Types/</id>
    <published>2018-08-24T03:24:45.000Z</published>
    <updated>2018-08-24T03:28:11.080Z</updated>
    
    <content type="html"><![CDATA[<p>我的分类是深度学习</p>]]></content>
    
    <summary type="html">
    
      Deep Learning
    
    </summary>
    
      <category term="深度学习" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>“test”</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/%E2%80%9Ctest%E2%80%9D/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/“test”/</id>
    <published>2018-08-24T01:12:08.000Z</published>
    <updated>2018-08-24T01:13:31.493Z</updated>
    
    <content type="html"><![CDATA[<p>大家好，这是我的第一个hexo!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;大家好，这是我的第一个hexo!&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/hello-world/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/hello-world/</id>
    <published>2018-08-24T00:48:48.099Z</published>
    <updated>2018-08-24T07:29:11.776Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
