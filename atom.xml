<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Next Legend!</title>
  
  <subtitle>一天进步一点点</subtitle>
  <link href="/NextLegend.github.io/atom.xml" rel="self"/>
  
  <link href="https://legendtianjin.github.io/NextLegend.github.io/"/>
  <updated>2018-09-03T14:29:15.133Z</updated>
  <id>https://legendtianjin.github.io/NextLegend.github.io/</id>
  
  <author>
    <name>赵小亮</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>汉字拼音转换工具_Python版</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/09/03/%E6%B1%89%E5%AD%97%E6%8B%BC%E9%9F%B3%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7-Python%E7%89%88/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/09/03/汉字拼音转换工具-Python版/</id>
    <published>2018-09-03T13:39:48.000Z</published>
    <updated>2018-09-03T14:29:15.133Z</updated>
    
    <content type="html"><![CDATA[<p><strong>先附上github的一张图片哈：</strong><br><img src="/NextLegend.github.io/2018/09/03/汉字拼音转换工具-Python版/汉字拼音转换工具_Python版/001.jpg" alt="汉字拼音转换工具_Python版"><br><strong>github地址如下：</strong><br><strong><a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener">https://github.com/mozillazg/python-pinyin</a></strong></p>]]></content>
    
    <summary type="html">
    
      小亮今天看到一篇不错的项目，现在和大家分享一下哈！该项目是基于hotoo/pinyin开发。将汉字转为拼音，可以用于汉字注音、排序、检索(Russian translation) 。详情请见下文！
    
    </summary>
    
      <category term="Python NLP" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Python-NLP/"/>
    
    
      <category term="NLP" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>2018算法工程师秋招集锦</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/09/03/2018%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%A7%8B%E6%8B%9B%E9%9B%86%E9%94%A6/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/09/03/2018算法工程师秋招集锦/</id>
    <published>2018-09-03T11:38:35.000Z</published>
    <updated>2018-09-03T11:38:35.441Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Learning Pyspark</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/25/Learning-Pyspark/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/25/Learning-Pyspark/</id>
    <published>2018-08-25T02:37:09.000Z</published>
    <updated>2018-08-25T03:35:58.810Z</updated>
    
    <content type="html"><![CDATA[<p><strong>我把书籍PDF版本和配套代码放在我的百度云里，附上链接地址：</strong><br><strong>百度云链接：<a href="https://pan.baidu.com/s/1EogSZ3mT4tAYZyqj6WprIg" target="_blank" rel="noopener">https://pan.baidu.com/s/1EogSZ3mT4tAYZyqj6WprIg</a> 密码：vsmv</strong><br><strong>下面介绍一下这本书：Learning Pyspark</strong><br><img src="/NextLegend.github.io/2018/08/25/Learning-Pyspark/Learning_Pyspark.png" alt="Learning Pyspark"></p><p>感谢您选择本书开始您的PySpark冒险，我希望您像我一样兴奋。当DennyLee第一次告诉我这本新书的时候很高兴 - 使Apache Spark成为最重要的事情之一精彩的平台，支持Java / Scala / JVM世界和Python（以及最近的R）世界。许多以前针对Spark的书都是专注于所有核心语言，或主要关注JVM语言，所以很高兴看到PySpark有机会用这样的专用书来发光经验丰富的Spark教育家。通过支持这两个不同的世界，我们是能够更有效地作为数据科学家和数据工程师一起工作窃取彼此社区的最佳想法。能够有机会审查其早期版本是一种荣幸这本书，只是增加了我对这个项目的兴奋。我有这个特权参加一些相同的会议和聚会，并观看作者向各种受众介绍Spark世界的新概念（从第一部分开始）定时器到老手），他们做了很好的工作，提炼他们的经验这本书。作者的经验从他们的作品中汲取了一切对所涉及主题的解释。除了简单介绍PySpark之外，他们还有还花时间查看来自社区的新闻包，例如GraphFrames和TensorFrames。我认为社区是决定时经常被忽视的组件之一使用什么工具，Python有一个很棒的社区，我很期待您加入了PythonSpark社区。所以，享受你的冒险;我知道你是与Denny Lee和TomekDrabas保持良好关系。我真的相信这一点一个多样化的Spark用户社区，我们将能够制作更好的工具。大家好，所以我希望能在一次会议，聚会或邮寄中见到你很快列出:)霍尔顿卡劳<br>附：<br>我欠丹尼一杯啤酒;如果你想给我买一个Bud Light lime（或lime-a-rita）我非常感激（虽然他可能不像我那样有趣）.<br><strong>本书作者：Tomasz Drabas</strong><br>Tomasz Drabas是一名为微软工作的数据科学家，目前居住在微软西雅图地区。 他在数据分析和数据科学方面拥有超过13年的经验在众多的领域：先进技术，航空公司，电信，金融，他在三大洲工作时获得了咨询：欧洲，澳大利亚，和北美。 在澳大利亚期间，Tomasz一直在攻读他的博士学位运营研究，重点关注选择建模和收益管理航空业的应用。</p>]]></content>
    
    <summary type="html">
    
      该书籍为2017年由Tomasz Drabas出版的英文原版Learning Pyspark。书籍技术路线是：在本地构建数据密集型应用程序并部署大规模使用Python和Spark 2.0的组合功能。
    
    </summary>
    
      <category term="Spark" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Spark/"/>
    
    
      <category term="大数据" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Python之禅</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/Python%E4%B9%8B%E7%A6%85/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/Python之禅/</id>
    <published>2018-08-24T13:47:44.000Z</published>
    <updated>2018-08-24T13:50:01.292Z</updated>
    
    <content type="html"><![CDATA[<p><strong>The Zen of Python, by Tim Peters</strong><br>Beautiful is better than ugly.<br>Explicit is better than implicit.<br>Simple is better than complex.<br>Complex is better than complicated.<br>Flat is better than nested.<br>Sparse is better than dense.<br>Readability counts.<br>Special cases aren’t special enough to break the rules.<br>Although practicality beats purity.<br>Errors should never pass silently.<br>Unless explicitly silenced.<br>In the face of ambiguity, refuse the temptation to guess.<br>There should be one– and preferably only one –obvious way to do it.<br>Although that way may not be obvious at first unless you’re Dutch.<br>Now is better than never.<br>Although never is often better than <em>right</em> now.<br>If the implementation is hard to explain, it’s a bad idea.<br>If the implementation is easy to explain, it may be a good idea.<br>Namespaces are one honking great idea – let’s do more of those!</p><p><strong>Tim Peters的Python之禅</strong><br>美丽胜过丑陋。<br>显式优于隐式。<br>简单比复杂更好。<br>复杂比复杂更好。<br>Flat优于嵌套。<br>稀疏优于密集。<br>可读性很重要。<br>特殊情况不足以打破规则。<br>虽然实用性胜过纯洁。<br>错误不应该默默地传递。<br>除非明确沉默。<br>面对模棱两可，拒绝猜测的诱惑。<br>应该有一个 - 最好只有一个 - 显而易见的方法。<br>虽然这种方式起初可能并不明显，除非你是荷兰人。<br>现在总比没有好。<br>虽然现在永远不会比*正确好。<br>如果实施很难解释，那是个坏主意。<br>如果实现很容易解释，那可能是个好主意。<br>命名空间是一个很棒的主意 - 让我们做更多的事情吧！</p>]]></content>
    
    <summary type="html">
    
      Tim Peters的Python之禅
    
    </summary>
    
      <category term="Python" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>GAN的理解与TensorFlow的实现</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/GAN%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8ETensorFlow%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/GAN的理解与TensorFlow的实现/</id>
    <published>2018-08-24T07:32:48.000Z</published>
    <updated>2018-08-24T09:54:54.959Z</updated>
    
    <content type="html"><![CDATA[<p>笔者信息：Next_Legend  QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络 高维信息处理<br>                                                                                                                                                                                                                                                                              ——2018.7.31于天津大学<br>一、前言<br>本文会从头介绍生成对抗式网络的一些内容，从生成式模型开始说起，到GAN的基本原理，InfoGAN，AC-GAN的基本科普，如果有任何有错误的地方，请随时喷，我刚开始研究GAN这块的内容，希望和大家一起学习。<br>二、生成式模型<br>何为生成式模型？在很多machine learning的教程或者公开课上，通常会把machine learning的算法分为两类： 生成式模型、判别式模型；其区别在于： 对于输入x，类别标签y，在生成式模型中估计其联合概率分布，而判别式模型估计其属于某类的条件概率分布。 常见的判别式模型包括：LogisticRegression， SVM, Neural Network等等，生成式模型包括：Naive Bayes， GMM， Bayesian Network， MRF 等等。<br>三、研究生成式模型的意义<br>生成式模型的特性主要包括以下几个方面：<br>    在应用数学和工程方面，生成式模型能够有效地表征高维数据分布；<br>    生成式模型能够作为一种技术手段辅助强化学习，能够有效表征强化学习模型中的state状态(这里不扩展，后面会跟RL的学习笔记)；<br>    对semi-supervised learning也有比较好的效果，能够在miss data下训练模型，并在miss data下给出相应地输出；<br>    在对于一个输入伴随多个输出的场景下，生成式模型也能够有效工作，而传统的机器学习方法通过最小化模型输出和期望输出的某个object function的值 无法训练单输入多输出的模型，而生成式模型，尤其是GAN能够hold住这种场景，一个典型的应用是通过场景预测video的下一帧。<br>生成式模型一些典型的应用：<br>    图像的超分辨率<br>    iGAN：Generative Visual Manipulation on the Natural Image Manifold<br>    图像转换<br>四、生成式模型族谱<br><img src="https://img-blog.csdn.net/20180804190740652?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>上图涵盖了基本的生成式模型的方法，主要按是否需要定义概率密度函数分为：<br>Explicit density models<br>explicit density models 又分为tractable explicit models和逼近的explicit model，怎么理解呢，tractable explicit model通常可以直接通过数学方法来建模求解，而基于逼近的explicit model通常无法直接对数据分布进行建模，可以利用数学里的一些近似方法来做数据建模， 通常基于逼近的explicit model分为确定性（变分方法：如VAE的lower bound）和随机性的方法（马尔科夫链蒙特卡洛方法）。<br>    VAE lower bound：<br>    <img src="https://img-blog.csdn.net/20180804190904726?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>    马尔科夫链蒙特卡洛方法（MCMC），一种经典的基于马尔科夫链的抽样方法，通过多次来拟合分布。比较好的教程：A Beginner’s Guide to Monte Carlo Markov Chain MCMC Analysis, An Introduction to MCMC for Machine Learning.<br>Implicit density models<br>无需定义明确的概率密度函数，代表方法包括马尔科夫链、生成对抗式网络（GAN），该系列方法无需定义数据分布的描述函数。</p><p>五、生成对抗式网络与其他生成式网络对比<br>生成对抗式网络（GAN）能够有效地解决很多生成式方法的缺点，主要包括：</p><ul><li>并行产生samples；</li><li>生成式函数的限制少，如无需合适马尔科夫采样的数据分布（Boltzmann machines），生成式函数无需可逆、latent code需与sample同维度（nonlinear ICA）；</li><li>无需马尔科夫链的方法（Boltzmann machines， GSNs）；</li><li>相对于VAE的方法，无需variational bound；<br>GAN比其他方法一般来说性能更好。</li><li>可以使用冒号来定义对齐方式：</li></ul><p>六、GAN工作原理<br>GAN主要由两部分构成：generator和discriminator，generator主要是从训练数据中产生相同分布的samples，而discriminator 则是判断输入是真实数据还是generator生成的数据，discriminator采用传统的监督学习的方法。这里我们可以这样类比，generator 是一个伪造假币的专业人士，discriminator是警察，generator的目的是制造出尽可能以假乱真的假钞，而discriminator是为了能 鉴别是否为假钞，最终整个gan会达到所谓的纳什均衡，Goodfellow在他的paperGAN的理解与TF的实现-小石头的码疯窝中有严格的数学证明，当$p_G$==$p_{data}$时达到 全局最优：<br><img src="https://img-blog.csdn.net/20180804191235601?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>另一个比较明显看得懂的图如下：<br><img src="https://img-blog.csdn.net/20180804191312769?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>图中黑色点线为真实数据分布$p_{data}$，绿色线为generator生成的数据分布$p_{G}$,而Discriminator就是蓝色点线，其目的是为了将$p_{data}$和$p_{G}$ 区分，(a)中是初始状态，然后会更新Discriminator中的参数，若干次step之后，Discriminator有了较大的判断力即到了(b)的状态，之后会更新G的模型使其生成的数据分布（绿色线）更加趋近与真实数据分布， 若干次G和D的模型参数更新后，理论上最终会达到(d)的状态即G能够产生和真实数据完全一致的分布(证明见上一张图)，如从随机数据分布生成人脸像。<br>七、如何训练GAN<br>因为GAN结构的不同，和常规训练一个dl model方法不同， 这里采用simultaneous SGD，每一个step中，会有两个两个梯度优化的 过程，一个是更新discriminator的参数来最小化$J_{(D)}$，一个是更新generator的参数来最小$J_{(G)}$，通常会选用Adam来作为最优化的优化器， 也有人建议可以不等次数地更新generator和discriminator（有相关工作提出，1：1的在实际中更有效：Adam: A Method for Stochastic Optimization） 如何训练GAN，在Goodfellow的GAN的tutorial还有一些代码中有更多的描述包括不同的cost function， 这里我就不详细展开了。<br>1、DCGAN<br>GAN出来后很多相关的应用和方法都是基于DCGAN的结构，DCGAN即”Deep Convolution GAN”，通常会有一些约定俗成的规则：<br><img src="https://img-blog.csdn.net/20180804191418817?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><ul><li>在Discriminator和generator中大部分层都使用batch normalization，而在最后一层时通常不会使用batch normalizaiton，目的 是为了保证模型能够学习到数据的正确的均值和方差；</li><li>因为会从random的分布生成图像，所以一般做需要增大图像的空间维度时如77-&gt;1414， 一般会使用strdie为2的deconv（transposed convolution）；</li><li>通常在DCGAN中会使用Adam优化算法而不是SGD。<br>2、各种GAN<br><img src="https://img-blog.csdn.net/2018080419152318?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>这里有个大神把各种gan的paper都做了一个统计AdversarialNetsPapers<br>这里大家有更多的兴趣可以直接去看对应的paper，我接下来会尽我所能描述下infogan和AC-GAN这两块的内容<br>3、InfoGAN<br>InfoGAN是一种能够学习disentangled representation的GAN，何为disentangled representation？比如人脸数据集中有各种不同的属性特点，如脸部表情、是否带眼睛、头发的风格眼珠的颜色等等，这些很明显的相关表示， InfoGAN能够在完全无监督信息（是否带眼睛等等）下能够学习出这些disentangled representation，而相对于传统的GAN，只需修改loss来最大化GAN的input的noise（部分fixed的子集）和最终输出之间的互信息。<br>4、原理<br>为了达到上面提到的效果，InfoGAN必须在input的noise来做一些文章，将noise vector划分为两部分：</li><li>z: 和原始的GAN input作用一致；</li><li>c: latent code，能够在之后表示数据分布中的disentangled representation<br>那么如何从latent code中学到相应的disentangled representation呢？ 在原始的GAN中，忽略了c这部分的影响，即GAN产生的数据分布满足$P_{G}(x|C)=P(x)$,为了保证能够利用c这部分信息， 作者提出这样一个假设：c与generator的输出相关程度应该很大，而在信息论中，两个数据分布的相关程度即互信息， 即generator的输出和input的c的$I(c;G(z,c))$应该会大。 所以，InfoGAN就变成如下的优化问题：<br><img src="https://img-blog.csdn.net/20180804191707262?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>因为互信息的计算需要后验概率的分布（下图红线部分），在实际中很难直接使用，因此，在实际训练中一般不会直接最大化$I(c;G(z,c))$<br><img src="https://img-blog.csdn.net/20180804191748702?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>这里作者采用和VAE类似的方法，增加一个辅助的数据分布为后验概率的low bound： 所以，这里互信息的计算如下：<br><img src="https://img-blog.csdn.net/20180804191813177?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>这里相关的证明就不深入了，有兴趣的可以去看看paper。<br>5、实验<br>我写的一版基于TensorFlow的Info-GAN实现：Info-GANburness/tensorflow-101 random的label信息，和对应生成的图像：<br><img src="https://img-blog.csdn.net/2018080419191142?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><img src="https://img-blog.csdn.net/20180804191920586?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>不同random变量控制产生同一class下的不同输出：<br><img src="https://img-blog.csdn.net/20180804191943725?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>6、AC-GAN<br>AC-GAN即auxiliary classifier GAN，对应的paper：[1610.09585] Conditional Image Synthesis With Auxiliary Classifier GANs, 如前面的示意图中所示，AC-GAN的Discriminator中会输出相应的class label的概率，然后更改loss fuction，增加class预测正确的概率， ac-gan是一个tensorflow相关的实现，基于作者自己开发的sugartensor，感觉和paper里面在loss函数的定义上差异，看源码的时候注意下，我这里有参考写了一个基于原生tensorflow的版本AC-GAN.<br>实验<br>各位有兴趣的可以拿代码在其他的数据集上也跑一跑，AC-GAN能够有效利用class label的信息，不仅可以在G时指定需要生成的image的label，同事该class label也能在Discriminator用来扩展loss函数，增加整个对抗网络的性能。 random的label信息，和对应生成的图像：<br><img src="https://img-blog.csdn.net/2018080419203481?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><img src="https://img-blog.csdn.net/20180804192043197?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>不同random变量控制产生同一class下的不同输出：<br><img src="https://img-blog.csdn.net/20180804192102877?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>七、总结<br>照例总结一下，本文中，我基本介绍了下生成式模型方法的各个族系派别，到GAN的基本内容，到InfoGAN、AC-GAN，大部分的工作都来自于阅读相关的paper，自己相关的工作就是 tensorflow下参考sugartensor的内容重现了InfoGAN、AC-GAN的相关内容。<br>当然，本人菜鸟一枚，难免有很多理解不到位的地方，写出来更多的是作为分享，让更多人了解GAN这块的内容，如果任何错误或不合适的地方，敬请在评论中指出，我们一起讨论一起学习 另外我的所有相关的代码都在github上:GAN,相信读一下无论是对TensorFlow的理解还是GAN的理解都会 有一些帮助，简单地参考mnist.py修改下可以很快的应用到你的数据集上，如果有小伙伴在其他数据集上做出有意思的实验效果的，欢迎分享。</li></ul><p>原文地址： <a href="http://www.leiphone.com/news/201702/GZsIbIb9V9AUGmb6.html" target="_blank" rel="noopener">http://www.leiphone.com/news/201702/GZsIbIb9V9AUGmb6.html</a></p>]]></content>
    
    <summary type="html">
    
      该教程前面主要讲解GAN网络的一些概念，后面会基于tensorflow实战，欢迎大家分享学习！
    
    </summary>
    
      <category term="Tensorflow实战深度学习" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Tensorflow%E5%AE%9E%E6%88%98%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Tensorflow" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>基于深度学习tensorflow实现文本分类任务的注意力机制</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/Tensorflow%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8ERNN%E7%9A%84%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/Tensorflow实现基于RNN的文本分类任务的注意力机制/</id>
    <published>2018-08-24T07:23:48.000Z</published>
    <updated>2018-08-24T09:55:23.841Z</updated>
    
    <content type="html"><![CDATA[<p>要点：<br>该教程为深度学习tensorflow实现文本分类任务的注意力机制，实现可视化注意力文本。<br>环境配置：<br>Wn10+CPU i7-6700<br>Pycharm2018<br>Tensorflow 1.8.0<br>Tensorboard 1.8.0<br>笔者信息：Next_Legend  QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络<br>                                                                                                 ——2018.8.8于天津大学</p><hr><p>一、下载代码<br>   该代码见笔者的资源下载部分<a href="https://download.csdn.net/download/jinyuan7708/10592063" target="_blank" rel="noopener">https://download.csdn.net/download/jinyuan7708/10592063</a><br>   代码不需要改动，只需要配置好环境和安装好相应的库，就可以训练和测试了。<br>二、相应的库文件<br>   tensorflow    1.8.0<br>   tensorboard  1.8.0<br>   numpy<br>   keras<br>   tqdm<br>三、工程目录文件<br>  <img src="https://img-blog.csdn.net/20180808222357233?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="工程目录文件"><br>  该项目主要包括attention.py       train.py     utils.py    visualize.py四个文件夹<br>  其中train.py文件是训练模型的文件，运行后会生成model.data-00000-of-00001、model.index、model.meta以及checkpoint文件，也就是训练生成的模型文件。<br>四、核心代码<br><img src="https://img-blog.csdn.net/20180808222935934?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br><img src="https://img-blog.csdn.net/20180808222945807?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br><img src="https://img-blog.csdn.net/20180808222954987?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br><strong>train.py文件代码</strong></p><php><pre><code>from __future__ import print_function, divisionimport numpy as npimport tensorflow as tffrom keras.datasets import imdbfrom tensorflow.contrib.rnn import GRUCellfrom tensorflow.python.ops.rnn import bidirectional_dynamic_rnn as bi_rnnfrom tqdm import tqdmfrom attention import attentionfrom utils import get_vocabulary_size, fit_in_vocabulary, zero_pad, batch_generatorNUM_WORDS = 10000INDEX_FROM = 3SEQUENCE_LENGTH = 250EMBEDDING_DIM = 100HIDDEN_SIZE = 150ATTENTION_SIZE = 50KEEP_PROB = 0.8BATCH_SIZE = 256NUM_EPOCHS = 3  # Model easily overfits without pre-trained words embeddings, that&apos;s why train for a few epochsDELTA = 0.5MODEL_PATH = &apos;./model&apos;# Load the data set(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS, index_from=INDEX_FROM)# Sequences pre-processingvocabulary_size = get_vocabulary_size(X_train)X_test = fit_in_vocabulary(X_test, vocabulary_size)X_train = zero_pad(X_train, SEQUENCE_LENGTH)X_test = zero_pad(X_test, SEQUENCE_LENGTH)# Different placeholderswith tf.name_scope(&apos;Inputs&apos;):batch_ph = tf.placeholder(tf.int32, [None, SEQUENCE_LENGTH], name=&apos;batch_ph&apos;)target_ph = tf.placeholder(tf.float32, [None], name=&apos;target_ph&apos;)seq_len_ph = tf.placeholder(tf.int32, [None], name=&apos;seq_len_ph&apos;)keep_prob_ph = tf.placeholder(tf.float32, name=&apos;keep_prob_ph&apos;)# Embedding layerwith tf.name_scope(&apos;Embedding_layer&apos;):embeddings_var = tf.Variable(tf.random_uniform([vocabulary_size, EMBEDDING_DIM], -1.0, 1.0), trainable=True)tf.summary.histogram(&apos;embeddings_var&apos;, embeddings_var)batch_embedded = tf.nn.embedding_lookup(embeddings_var, batch_ph)# (Bi-)RNN layer(-s)rnn_outputs, _ = bi_rnn(GRUCell(HIDDEN_SIZE), GRUCell(HIDDEN_SIZE),                    inputs=batch_embedded, sequence_length=seq_len_ph, dtype=tf.float32)tf.summary.histogram(&apos;RNN_outputs&apos;, rnn_outputs)# Attention layerwith tf.name_scope(&apos;Attention_layer&apos;):attention_output, alphas = attention(rnn_outputs, ATTENTION_SIZE, return_alphas=True)tf.summary.histogram(&apos;alphas&apos;, alphas)# Dropoutdrop = tf.nn.dropout(attention_output, keep_prob_ph)# Fully connected layerwith tf.name_scope(&apos;Fully_connected_layer&apos;):W = tf.Variable(tf.truncated_normal([HIDDEN_SIZE * 2, 1], stddev=0.1))  # Hidden size is multiplied by 2 for Bi-RNNb = tf.Variable(tf.constant(0., shape=[1]))y_hat = tf.nn.xw_plus_b(drop, W, b)y_hat = tf.squeeze(y_hat)tf.summary.histogram(&apos;W&apos;, W)with tf.name_scope(&apos;Metrics&apos;):    # Cross-entropy loss and optimizer initialization    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_hat, labels=target_ph))    tf.summary.scalar(&apos;loss&apos;, loss) optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)# Accuracy metricaccuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(tf.sigmoid(y_hat)), target_ph), tf.float32))tf.summary.scalar(&apos;accuracy&apos;, accuracy)merged = tf.summary.merge_all()train_batch_generator = batch_generator(X_train, y_train, BATCH_SIZE)test_batch_generator = batch_generator(X_test, y_test, BATCH_SIZE)train_writer = tf.summary.FileWriter(&apos;./logdir/train&apos;, accuracy.graph)test_writer = tf.summary.FileWriter(&apos;./logdir/test&apos;, accuracy.graph)session_conf = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))saver = tf.train.Saver()if __name__ == &quot;__main__&quot;:with tf.Session(config=session_conf) as sess:    sess.run(tf.global_variables_initializer())    print(&quot;Start learning...&quot;)    for epoch in range(NUM_EPOCHS):        loss_train = 0        loss_test = 0        accuracy_train = 0        accuracy_test = 0        print(&quot;epoch: {}\t&quot;.format(epoch), end=&quot;&quot;)        # Training        num_batches = X_train.shape[0] // BATCH_SIZE        for b in tqdm(range(num_batches)):            x_batch, y_batch = next(train_batch_generator)            seq_len = np.array([list(x).index(0) + 1 for x in x_batch])  # actual lengths of sequences            loss_tr, acc, _, summary = sess.run([loss, accuracy, optimizer, merged],                                                feed_dict={batch_ph: x_batch,                                                           target_ph: y_batch,                                                           seq_len_ph: seq_len,                                                           keep_prob_ph: KEEP_PROB})            accuracy_train += acc            loss_train = loss_tr * DELTA + loss_train * (1 - DELTA)            train_writer.add_summary(summary, b + num_batches * epoch)        accuracy_train /= num_batches        # Testing        num_batches = X_test.shape[0] // BATCH_SIZE        for b in tqdm(range(num_batches)):            x_batch, y_batch = next(test_batch_generator)            seq_len = np.array([list(x).index(0) + 1 for x in x_batch])  # actual lengths of sequences            loss_test_batch, acc, summary = sess.run([loss, accuracy, merged],                                                     feed_dict={batch_ph: x_batch,                                                                target_ph: y_batch,                                                                seq_len_ph: seq_len,                                                                keep_prob_ph: 1.0})            accuracy_test += acc            loss_test += loss_test_batch            test_writer.add_summary(summary, b + num_batches * epoch)        accuracy_test /= num_batches        loss_test /= num_batches        print(&quot;loss: {:.3f}, val_loss: {:.3f}, acc: {:.3f}, val_acc: {:.3f}&quot;.format(            loss_train, loss_test, accuracy_train, accuracy_test        ))    train_writer.close()    test_writer.close()    saver.save(sess, MODEL_PATH)    print(&quot;Run &apos;tensorboard --logdir=./logdir&apos; to checkout tensorboard logs.&quot;)</code></pre><p></p></php><br>五、训练过程<br>   <img src="https://img-blog.csdn.net/20180808224427275?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>   笔者由于使用的 CPU来进行训练，所以速度比较慢，感兴趣的朋友可以考虑使用GPU来计算，可以大大减少训练模型的时间。如果不会搭建gpu环境的小伙伴可以参考我的另一篇Tensorflow gpu环境搭建 ，附上地址哈：<br>   <a href="https://blog.csdn.net/jinyuan7708/article/details/79642924" target="_blank" rel="noopener">https://blog.csdn.net/jinyuan7708/article/details/79642924</a><br>六、训练结果<br>  <img src="https://img-blog.csdn.net/20180808224902778?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="训练生成的model文件"><br>七、Tensorboard可视化<br><img src="https://img-blog.csdn.net/20180808225017120?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="accuracy"><br><img src="https://img-blog.csdn.net/20180808225026854?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="loss"><br><img src="https://img-blog.csdn.net/20180808225040674?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="计算图"><br>八、visualization可视化结果<br>得到模型后，再继续执行visualize.py文件，生成结果可视化。如下图：<br><img src="https://img-blog.csdn.net/20180808225248673?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""><br>至此，我们的教程就结束啦，代码等文件我上传到我的blog下载资源部分，欢迎大家下载批评指正哈!<br>代码地址：<a href="https://download.csdn.net/download/jinyuan7708/10592063" target="_blank" rel="noopener">https://download.csdn.net/download/jinyuan7708/10592063</a><p></p>]]></content>
    
    <summary type="html">
    
      该教程为深度学习tensorflow实现文本分类任务的注意力机制，实现可视化注意力文本。
    
    </summary>
    
      <category term="Tensorflow实战深度学习" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/Tensorflow%E5%AE%9E%E6%88%98%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Tensorflow" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>中英文NLP集成型工具汇总</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/%E4%B8%AD%E8%8B%B1%E6%96%87NLP%E9%9B%86%E6%88%90%E5%9E%8B%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/中英文NLP集成型工具汇总/</id>
    <published>2018-08-24T07:22:48.000Z</published>
    <updated>2018-08-24T09:56:08.365Z</updated>
    
    <content type="html"><![CDATA[<p><strong>该文档简单总结了一下集成的中英文NLP工具，分享给NLP领域的大家！</strong><br>笔者信息：Next_Legend QQ:1219154092 机器学习 自然语言处理 计算机视觉 深度学习<br>——2018.8.19于天津大学</p><hr><p><strong>1、面向研究的StanfordNLP(Java) (CoreNLP/Parder/POS Tager/NER…) <a href="https://nlp.stanford.edu/software/index.shtml" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819205836357?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>2、面向应用的SpaCy(Python) <a href="https://spacy.io/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819205650448?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>3、哈工大语言技术平台LTP(C++) <a href="https://github.com/HIT-SCIR/ltp" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819205956673?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>4、本土的HanLP(Java) <a href="http://hanlp.hankcs.com/?sentence=%E6%88%91%E7%88%B1%E4%BD%A0%E4%B8%AD%E5%9B%BD%EF%BC%8C%E6%88%91%E5%9C%A8%E5%A4%A9%E6%B4%A5%E5%A4%A7%E5%AD%A6%EF%BC%8C%E6%88%91%E7%88%B1%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%82" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/2018081921031468?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>5、轻量非主流的xmnlp(Python) <a href="https://github.com/SeanLee97/xmnlp" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819210436793?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>6、相对零散的THUNLP开放项目 <a href="https://github.com/thunlp" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819210536217?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>7、复旦大学NLP <a href="http://nlp.fudan.edu.cn/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819210840388?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>8、清华大学NLP <a href="http://thulac.thunlp.org/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819211018822?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>9、TEXTBLOG <a href="https://textblob.readthedocs.io/en/dev/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819211200578?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>10、PyNLPIR <a href="https://pypi.org/project/PyNLPIR/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819211324571?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>11、Polyglot <a href="https://polyglotclub.com/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/2018081921152564?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>12、NLTK <a href="http://www.nltk.org/" target="_blank" rel="noopener">网页链接</a></strong><br><img src="https://img-blog.csdn.net/20180819211652437?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>其他的NLP工具小编暂时没有了解，欢迎有使用经验的同学朋友补充！ </strong></p>]]></content>
    
    <summary type="html">
    
      该文档简单总结了一下集成的中英文NLP工具，分享给NLP领域的大家！
    
    </summary>
    
      <category term="NLP" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/NLP/"/>
    
    
      <category term="自然语言处理" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>算法_NLP_深度学习_机器学习面试笔记</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/%E7%AE%97%E6%B3%95_NLP_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/算法_NLP_深度学习_机器学习面试笔记/</id>
    <published>2018-08-24T07:20:48.000Z</published>
    <updated>2018-08-24T09:55:46.446Z</updated>
    
    <content type="html"><![CDATA[<p>笔者信息：Next_Legend QQ:1219154092 机器学习 自然语言处理 图像处理 深度学习<br>——2018.8.13于天津大学</p><hr><div class="article_content clearfix csdn-tracking-statistics" id="article_content" data-mod="popu_307" data-dsm="post" data-pid="blog"><br>                    <div class="markdown_views"><br>                <p><strong>GitHub 地址</strong>：<a href="https://github.com/imhuay/CS_Interview_Notes-Chinese" target="_blank" rel="nofollow">https://github.com/imhuay/CS_Interview_Notes-Chinese</a></p><br><br><p>深度学习/机器学习面试问题整理，想法来源于这个<a href="https://github.com/elviswf/DeepLearningBookQA_cn" target="_blank" rel="nofollow">仓库</a>. <br><br>- 该仓库整理了“花书”《深度学习》中的一些常见问题，其中部分偏理论的问题没有收录，如有需要可以浏览原仓库。</p><br><br><p>此外，还包括我看到的所有机器学习/深度学习面经中的问题。除了其中 DL/ML 相关的，其他与算法岗相关的计算机知识也会记录。</p><br><br><p>但是不会包括如前端/测试/JAVA/Android等岗位中有关的问题。</p><br><br><br><br><h2 id="roadmap"><a name="t0"></a>RoadMap</h2><br><br><ul><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/数学" target="_blank" rel="nofollow">数学</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/数学/微积分的本质.md" target="_blank" rel="nofollow">微积分的本质</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/数学/深度学习的核心.md" target="_blank" rel="nofollow">深度学习的核心</a></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理" target="_blank" rel="nofollow">自然语言处理</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-词向量.md" target="_blank" rel="nofollow">词向量</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-词向量.md#word2vec" target="_blank" rel="nofollow">Word2Vec</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-词向量.md#glove" target="_blank" rel="nofollow">GloVe</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-词向量.md#fasttext" target="_blank" rel="nofollow">FastText</a></li><br><li>WordRank TODO</li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-序列建模.md" target="_blank" rel="nofollow">序列建模</a> TODO</li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/自然语言处理/专题-工具库.md" target="_blank" rel="nofollow">工具库</a></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习" target="_blank" rel="nofollow">机器学习-深度学习</a> <br><br><ul><li>公共基础 <br><br><ul><li>背景知识</li><br><li>损失函数</li></ul></li><br><li>深度学习 <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习/DL专题-深度学习基础.md" target="_blank" rel="nofollow">深度学习基础</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习/DL专题-《深度学习》整理.md" target="_blank" rel="nofollow">《深度学习》整理</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习/DL专题-CNN.md" target="_blank" rel="nofollow">CNN专题</a></li></ul></li><br><li>机器学习 <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习/ML专题-机器学习算法.md" target="_blank" rel="nofollow">机器学习算法</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习-深度学习/ML专题-机器学习实践.md" target="_blank" rel="nofollow">机器学习实践</a></li></ul></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/算法" target="_blank" rel="nofollow">算法</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/算法/题解-剑指Offer.md" target="_blank" rel="nofollow">题解-剑指Offer</a></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/编程语言" target="_blank" rel="nofollow">编程语言</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/编程语言/Cpp专题-基础知识.md" target="_blank" rel="nofollow">Cpp专题-基础知识</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/编程语言/Cpp专题-左值与右值.md" target="_blank" rel="nofollow">Cpp专题-左值与右值</a></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/笔试面经" target="_blank" rel="nofollow">笔试面经</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/项目经验" target="_blank" rel="nofollow">项目经验</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/code" target="_blank" rel="nofollow">code</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/code/工具库" target="_blank" rel="nofollow">工具库</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/code/工具库/gensim/FastText.py" target="_blank" rel="nofollow">gensim.FastText 的使用</a></li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/code/倒排索引" target="_blank" rel="nofollow">倒排索引</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/code/tf-基础" target="_blank" rel="nofollow">Tensorflow 基础</a> TODO</li></ul></li><br><li>各公司<a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/招聘要求.md" target="_blank" rel="nofollow">招聘要求</a></li><br></ul><br><br><h2 id="必备清单-todo"><a name="t1"></a>必备清单 TODO</h2><br><br><ul><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/深度学习/README.md" target="_blank" rel="nofollow">深度学习</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/深度学习/README.md#反向传播算法" target="_blank" rel="nofollow">反向传播算法</a></li><br><li><a href="#梯度下降法" target="_self" rel="nofollow">梯度下降法</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/项目经验/README.md" target="_blank" rel="nofollow">深度学习实践</a>（项目经验）</li><br><li>相关代码 TODO</li></ul></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习/README.md" target="_blank" rel="nofollow">机器学习算法</a> <br><br><ul><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习/README.md#逻辑斯蒂回归" target="_blank" rel="nofollow">逻辑斯蒂回归</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习/README.md#支持向量机" target="_blank" rel="nofollow">支持向量机</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习/README.md#adaboost-算法" target="_blank" rel="nofollow">AdaBoost 算法</a></li><br><li><a href="https://github.com/imhuay/CS_Interview_Notes-Chinese/blob/master/机器学习/README.md#梯度提升决策树-gbdt" target="_blank" rel="nofollow">GBDT 梯度提升决策树</a></li><br><li>相关代码 TODO</li></ul></li><br><li>计算机基础 <br><br><ul><li><a href="https://github.com/imhuay/Algorithm_for_Interview-Chinese/tree/master/Algorithm_for_Interview/_必背算法" target="_blank" rel="nofollow">必背算法</a></li><br><li>Python 常识 TODO</li><br><li>C++ 常识 TODO</li></ul></li><br></ul><br><br><br><br><h2 id="欢迎分享你在深度学习机器学习面试过程中遇见的问题"><a name="t2"></a><strong>欢迎分享你在深度学习/机器学习面试过程中遇见的问题！</strong></h2><br><br><p>你可以直接以你遇到的问题作为 issue 标题，然后分享你的回答或者其他参考资料。</p><br><br><p>当然，你也可以直接创建 PR，分享问题的同时改正我的错误！</p><br><br><blockquote><br>  <p>我会经常修改文档的结构（特别是代码的链接）。如果文中有链接失效，请告诉我！ <br><br>  文档中大部分链接都是指向仓库内的文件或标记；涉及编程代码的链接会指向我的另一个仓库（<a href="https://github.com/imhuay/Algorithm_for_Interview-Chinese" target="_blank" rel="nofollow">Algorithm_for_Interview</a>）</p><br></blockquote><br><br><br><br><h3 id="reference"><a name="t3"></a>Reference</h3><br><br><ul><br><li>exacity/<a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="nofollow">deeplearningbook-chinese</a>: 深度学习中文版 </li><br><li>elviswf/<a href="https://github.com/elviswf/DeepLearningBookQA_cn" target="_blank" rel="nofollow">DeepLearningBookQA_cn</a>: 深度学习面试问题 回答对应的DeepLearning中文版页码</li><br><li>huihut/<a href="https://github.com/huihut/interview" target="_blank" rel="nofollow">interview: C/C++面试知识总结</a> </li><br><li>七月在线：<a href="https://blog.csdn.net/v_july_v" target="_blank" rel="nofollow">结构之法 算法之道</a> - CSDN博客</li><br><li>在线 LaTeX 公式编辑器 <a href="http://www.codecogs.com/latex/eqneditor.php" target="_blank" rel="nofollow">http://www.codecogs.com/latex/eqneditor.php</a></li><br><li>GitHub 搜索：<a href="https://github.com/search?q=deep+learning+interview" target="_blank" rel="nofollow">Deep Learning Interview</a></li><br><li>GitHub 搜索：<a href="https://github.com/search?q=machine+learning+interview" target="_blank" rel="nofollow">Machine Learning Interview</a> <br><br><ul><li>geekcircle/<a href="https://github.com/geekcircle/machine-learning-interview-qa" target="_blank" rel="nofollow">machine-learning-interview-qa</a>: 人工智能-机器学习笔试面试题解析 </li></ul></li><br><li><a href="https://www.nowcoder.com/discuss?type=2&amp;order=0" target="_blank" rel="nofollow">牛客网-讨论区</a></li><br></ul>            </div><br>            <link href="https://csdnimg.cn/release/phoenix/template/css/markdown_views-ea0013b516.css" rel="stylesheet"><br>                </div>]]></content>
    
    <summary type="html">
    
      该集锦是2018年机器学习以及深度学习算法岗位笔记汇总，欢迎大家学习交流！
    
    </summary>
    
      <category term="面试集锦" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E9%9D%A2%E8%AF%95%E9%9B%86%E9%94%A6/"/>
    
    
      <category term="算法" scheme="https://legendtianjin.github.io/NextLegend.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>基于python+opencv的图像目标区域自动提取</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/%E5%9F%BA%E4%BA%8Epython+opencv%E7%9A%84%E5%9B%BE%E5%83%8F%E7%9B%AE%E6%A0%87%E5%8C%BA%E5%9F%9F%E8%87%AA%E5%8A%A8%E6%8F%90%E5%8F%96%EF%BC%88%E6%9C%AC%E9%A1%B9%E7%9B%AE%E4%B8%BA%E6%8F%90%E5%8F%96%E7%BA%B8%E5%BC%A0%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%89/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/基于python+opencv的图像目标区域自动提取（本项目为提取纸张中的内容）/</id>
    <published>2018-08-24T07:17:48.000Z</published>
    <updated>2018-08-24T07:18:06.447Z</updated>
    
    <content type="html"><![CDATA[<p>要点：<br>该教程为基于python+opencv的图像目标区域自动提取，实现自动提取一张照片中的纸张内容<br>环境配置：<br>Wn10+CPU i7-6700<br>Pycharm2018<br>opencv-python 3.4.2.17<br>numpy 1.14.5<br>笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络<br>                                                ——2018.8.12于天津大学</p><p>该项目的代码在笔者的资源仓库中，代码地址：<br><a href="https://download.csdn.net/download/jinyuan7708/10599212" target="_blank" rel="noopener">基于python+opencv的图像目标区域自动提取</a></p><hr><p>一、项目背景<br>一张照片中的感兴趣区域总是沿着x,y,z三个轴都有一定倾斜（如下图），要想把照片翻转到平行位置，需要进行透视变换，而透视变换需要同一像素点变换前后的坐标。由此可以想到，提取矩形区域四个角的坐标作为变换前的坐标，变换后的坐标可以设为照片的四个角落，经过投影变换，矩形区域将会翻转并充满图像。<br><strong>因此我们要解决的问题变为：提取矩形的四个角落、进行透视变换。</strong><img src="https://img-blog.csdn.net/20180812200443662?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><p>二、提取矩形角落坐标<br>矩形的检测主要是提取边缘，图片显示部分的亮度通常高于周围环境，我们可以将图片阈值化，将图片部分与周围环境明显的分别开来，这对后边的边缘检测非常有帮助。<br><strong>检测矩形并提取坐标需要对图像进行预处理、边缘检测、提取轮廓、检测凸包、角点检测。</strong><br>1、预处理转为灰度图<br>由于手机拍摄的照片像素可能会很高，为了加快处理速度，我们首先将图像转化为灰度图<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">image</span> = cv2.imread(Config.src)</span><br><span class="line">gray = cv2.cvtColor(<span class="built_in">image</span>, cv2.COLOR_BGR2GRAY)</span><br><span class="line">srcWidth, srcHeight, channels = <span class="built_in">image</span>.<span class="built_in">shape</span></span><br><span class="line"><span class="built_in">print</span>(srcWidth, srcHeight)</span><br></pre></td></tr></table></figure></p><p>2、中值滤波</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">binary</span> = cv2.medianBlur(gray,<span class="number">7</span>)</span><br></pre></td></tr></table></figure><p>3、转化为二值图像<br><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ret, <span class="built_in">binary</span> = cv2.threshold(<span class="built_in">binary</span>, Config.threshold_thresh, <span class="number">255</span>, cv2.THRESH_BINARY)</span><br><span class="line">cv2.imwrite(<span class="string">"1-threshold.png"</span>, <span class="built_in">binary</span>, [<span class="built_in">int</span>(cv2.IMWRITE_PNG_COMPRESSION), <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p><p>此时图片已经变成了这个样子：<br><img src="https://img-blog.csdn.net/20180812194831910?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>可见纸张页面部分已经与背景环境分离开来。<br>4、边缘检测与轮廓处理<br>我们用Canny算子边缘检测，提取轮廓</p><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># canny提取轮廓</span></span><br><span class="line"><span class="built_in">binary</span> = cv2.Canny(<span class="built_in">binary</span>, <span class="number">0</span>, <span class="number">60</span>, apertureSize = <span class="number">3</span>)</span><br><span class="line">cv2.imwrite(<span class="string">"3-canny.png"</span>, <span class="built_in">binary</span>, [<span class="built_in">int</span>(cv2.IMWRITE_PNG_COMPRESSION), <span class="number">9</span>])</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdn.net/20180812195304944?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><strong>提取轮廓后，拟合外接多边形（矩形）</strong></p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 提取轮廓后，拟合外接多边形（矩形）</span></span><br><span class="line"><span class="literal">_</span>,contours,<span class="literal">_</span> = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">print(<span class="string">"len(contours)=%d"</span>%(len(contours)))</span><br></pre></td></tr></table></figure><p>5、提取面积最大的轮廓并用多边形将轮廓包围</p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> idx,c in enumerate(contours):</span><br><span class="line">    <span class="keyword">if</span> len(c) &lt; Config.min_contours:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    epsilon = Config.epsilon_start</span><br><span class="line">    <span class="keyword">while</span> True:</span><br><span class="line">        approx = cv2.approxPolyDP(c,epsilon,True)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"idx,epsilon,len(approx),len(c)=%d,%d,%d,%d"</span>%(idx,epsilon,len(approx),len(c)))</span><br><span class="line">        <span class="keyword">if</span> (len(approx) &lt; <span class="number">4</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> math.fabs(cv2.contourArea(approx)) &gt; Config.min_area:</span><br><span class="line">            <span class="keyword">if</span> (len(approx) &gt; <span class="number">4</span>):</span><br><span class="line">                epsilon += Config.epsilon_step</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">"epsilon=%d, count=%d"</span>%(epsilon,len(approx)))</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                #<span class="keyword">for</span> p in approx:</span><br><span class="line">                #    cv2.circle(<span class="built_in">binary</span>,(p[<span class="number">0</span>][<span class="number">0</span>],p[<span class="number">0</span>][<span class="number">1</span>]),<span class="number">8</span>,(<span class="number">255</span>,<span class="number">255</span>,<span class="number">0</span>),thickness=<span class="number">-1</span>)</span><br><span class="line">                approx = approx.reshape((<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line">                # 点重排序, [top-left, top-right, bottom-right, bottom-left]</span><br><span class="line">                src_rect = order_points(approx)</span><br><span class="line"></span><br><span class="line">                cv2.drawContours(<span class="built_in">image</span>, c, <span class="number">-1</span>, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>),<span class="number">1</span>)</span><br><span class="line">                cv2.<span class="built_in">line</span>(<span class="built_in">image</span>, (src_rect[<span class="number">0</span>][<span class="number">0</span>],src_rect[<span class="number">0</span>][<span class="number">1</span>]),(src_rect[<span class="number">1</span>][<span class="number">0</span>],src_rect[<span class="number">1</span>][<span class="number">1</span>]),<span class="built_in">color</span>=(<span class="number">100</span>,<span class="number">255</span>,<span class="number">100</span>))</span><br><span class="line">                cv2.<span class="built_in">line</span>(<span class="built_in">image</span>, (src_rect[<span class="number">2</span>][<span class="number">0</span>],src_rect[<span class="number">2</span>][<span class="number">1</span>]),(src_rect[<span class="number">1</span>][<span class="number">0</span>],src_rect[<span class="number">1</span>][<span class="number">1</span>]),<span class="built_in">color</span>=(<span class="number">100</span>,<span class="number">255</span>,<span class="number">100</span>))</span><br><span class="line">                cv2.<span class="built_in">line</span>(<span class="built_in">image</span>, (src_rect[<span class="number">2</span>][<span class="number">0</span>],src_rect[<span class="number">2</span>][<span class="number">1</span>]),(src_rect[<span class="number">3</span>][<span class="number">0</span>],src_rect[<span class="number">3</span>][<span class="number">1</span>]),<span class="built_in">color</span>=(<span class="number">100</span>,<span class="number">255</span>,<span class="number">100</span>))</span><br><span class="line">                cv2.<span class="built_in">line</span>(<span class="built_in">image</span>, (src_rect[<span class="number">0</span>][<span class="number">0</span>],src_rect[<span class="number">0</span>][<span class="number">1</span>]),(src_rect[<span class="number">3</span>][<span class="number">0</span>],src_rect[<span class="number">3</span>][<span class="number">1</span>]),<span class="built_in">color</span>=(<span class="number">100</span>,<span class="number">255</span>,<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">                # 获取最小矩形包络</span><br><span class="line">                <span class="built_in">rect</span> = cv2.minAreaRect(approx)</span><br><span class="line">                # <span class="built_in">rect</span> = cv2.maxAreaRect(approx)</span><br><span class="line">                <span class="built_in">box</span> = cv2.boxPoints(<span class="built_in">rect</span>)</span><br><span class="line">                <span class="built_in">box</span> = np.int0(<span class="built_in">box</span>)</span><br><span class="line">                <span class="built_in">box</span> = <span class="built_in">box</span>.reshape(<span class="number">4</span>,<span class="number">2</span>)</span><br><span class="line">                <span class="built_in">box</span> = order_points(<span class="built_in">box</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">"approx-&gt;box"</span>)</span><br><span class="line">                <span class="built_in">print</span>(approx)</span><br><span class="line">                <span class="built_in">print</span>(src_rect)</span><br><span class="line">                <span class="built_in">print</span>(<span class="built_in">box</span>)</span><br><span class="line">                w,h = point_distance(<span class="built_in">box</span>[<span class="number">0</span>],<span class="built_in">box</span>[<span class="number">1</span>]), \</span><br><span class="line">                      point_distance(<span class="built_in">box</span>[<span class="number">1</span>],<span class="built_in">box</span>[<span class="number">2</span>])</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">"w,h=%d,%d"</span>%(w,h))</span><br></pre></td></tr></table></figure><p>6、 透视变换</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dst_rect = np.array([</span><br><span class="line">                    [<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                    [w - <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                    [w - <span class="number">1</span>, h - <span class="number">1</span>],</span><br><span class="line">                    [<span class="number">0</span>, h - <span class="number">1</span>]],</span><br><span class="line">                    dtype=<span class="string">"float32"</span>)</span><br><span class="line">                M = cv2.getPerspectiveTransform(src_rect, dst_rect)</span><br><span class="line">                warped = cv2.warpPerspective(image, M, (w, h))</span><br><span class="line">                cv2.imwrite(<span class="string">"transfer%d.png"</span>%idx, warped, [int(cv2.IMWRITE_PNG_COMPRESSION), <span class="number">9</span>])</span><br><span class="line">                break</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdn.net/20180812195725900?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>总结<br>本项目利用了照片背景亮度较高的特点，通过二值化突出轮廓提取坐标，进行透视变换。但是局限性在于，如果矩形的亮度与背景相差不大，就很难用这种方法检测到轮廓还需要算法优化。该项目的代码在笔者的资源仓库中，代码地址：<br><a href="https://download.csdn.net/download/jinyuan7708/10599212" target="_blank" rel="noopener">基于python+opencv的图像目标区域自动提取</a></p>]]></content>
    
    <summary type="html">
    
      该教程为基于python+opencv的图像目标区域自动提取，实现自动提取一张照片中的纸张内容
    
    </summary>
    
      <category term="计算机视觉" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
  </entry>
  
  <entry>
    <title>基于Kears的Attention实战</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/%E5%9F%BA%E4%BA%8EKeras%E7%9A%84attention%E5%AE%9E%E6%88%98/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/基于Keras的attention实战/</id>
    <published>2018-08-24T03:34:48.000Z</published>
    <updated>2018-08-24T03:34:13.116Z</updated>
    
    <content type="html"><![CDATA[<p>要点：<br>该教程为基于Kears的Attention实战，环境配置：<br>Wn10+CPU i7-6700<br>Pycharm 2018<br>python 3.6<br>numpy 1.14.5<br>Keras 2.0.2<br>Matplotlib 2.2.2<br><strong><em>强调：各种库的版本型号一定要配置对，因为Keras以及Tensorflow升级更新比较频繁，很多函数更新后要么更换了名字，要么没有这个函数了，所以大家务必重视。</em></strong><br><strong>相关代码我放在了我的代码仓库里哈，欢迎大家下载，这里附上地址：<a href="https://download.csdn.net/download/jinyuan7708/10617858" target="_blank" rel="noopener">基于Kears的Attention实战</a></strong><br>笔者信息：Next_Legend QQ:1219154092 人工智能 自然语言处理 图像处理 神经网络<br>——2018.8.21于天津大学</p><hr><p>一、导读<br>最近两年，尤其在今年，注意力机制(Attention)及其变种Attention逐渐热了起来，在很多顶会Paper中都或多或少的用到了attention,所以小编出于好奇，整理了这篇基于Kears的Attention实战，本教程仅从代码的角度来看Attention。通过一个简单的例子，探索Attention机制是如何在模型中起到特征选择作用的。<br>二、代码实战（一）<br>1、导入相关库文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> attention_utils <span class="keyword">import</span> get_activations, get_data</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1337</span>)  <span class="comment"># for reproducibility</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense, merge</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure></p><p>2、数据生成函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(n, input_dim, attention_column=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Data generation. x is purely random except that it's first value equals the target y.</span></span><br><span class="line"><span class="string">    In practice, the network should learn that the target = x[attention_column].</span></span><br><span class="line"><span class="string">    Therefore, most of its attention should be focused on the value addressed by attention_column.</span></span><br><span class="line"><span class="string">    :param n: the number of samples to retrieve.</span></span><br><span class="line"><span class="string">    :param input_dim: the number of dimensions of each element in the series.</span></span><br><span class="line"><span class="string">    :param attention_column: the column linked to the target. Everything else is purely random.</span></span><br><span class="line"><span class="string">    :return: x: model inputs, y: model targets</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    x = np.random.standard_normal(size=(n, input_dim))</span><br><span class="line">    y = np.random.randint(low=<span class="number">0</span>, high=<span class="number">2</span>, size=(n, <span class="number">1</span>))</span><br><span class="line">    x[:, attention_column] = y[:, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure><p>3、模型定义函数<br>将输入进行一次变换后，计算出Attention权重，将输入乘上Attention权重，获得新的特征。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">()</span>:</span></span><br><span class="line">    inputs = Input(shape=(input_dim,))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ATTENTION PART STARTS HERE</span></span><br><span class="line">    attention_probs = Dense(input_dim, activation=<span class="string">'softmax'</span>, name=<span class="string">'attention_vec'</span>)(inputs)</span><br><span class="line">    attention_mul =merge([inputs, attention_probs], output_shape=<span class="number">32</span>, name=<span class="string">'attention_mul'</span>, mode=<span class="string">'mul'</span>)</span><br><span class="line">    <span class="comment"># ATTENTION PART FINISHES HERE</span></span><br><span class="line"></span><br><span class="line">    attention_mul = Dense(<span class="number">64</span>)(attention_mul)</span><br><span class="line">    output = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(attention_mul)</span><br><span class="line">    model = Model(input=[inputs], output=output)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p><p>4、主函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    N = <span class="number">10000</span></span><br><span class="line">    inputs_1, outputs = get_data(N, input_dim)</span><br><span class="line"></span><br><span class="line">    m = build_model()</span><br><span class="line">    m.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">    print(m.summary())</span><br><span class="line"></span><br><span class="line">    m.fit([inputs_1], outputs, epochs=<span class="number">20</span>, batch_size=<span class="number">64</span>, validation_split=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    testing_inputs_1, testing_outputs = get_data(<span class="number">1</span>, input_dim)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Attention vector corresponds to the second matrix.</span></span><br><span class="line">    <span class="comment"># The first one is the Inputs output.</span></span><br><span class="line">    attention_vector = get_activations(m, testing_inputs_1,</span><br><span class="line">                                       print_shape_only=<span class="keyword">True</span>,</span><br><span class="line">                                       layer_name=<span class="string">'attention_vec'</span>)[<span class="number">0</span>].flatten()</span><br><span class="line">    print(<span class="string">'attention ='</span>, attention_vector)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot part.</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">    pd.DataFrame(attention_vector, columns=[<span class="string">'attention (%)'</span>]).plot(kind=<span class="string">'bar'</span>,</span><br><span class="line">                                                                   title=<span class="string">'Attention Mechanism as '</span></span><br><span class="line">                                                                         <span class="string">'a function of input'</span></span><br><span class="line">                                                                         <span class="string">' dimensions.'</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p><p>5、运行结果<br>代码中，attention_column为1，也就是说，label只与数据的第1个特征相关。从运行结果中可以看出，Attention权重成功地获取了这个信息。<br><img src="https://img-blog.csdn.net/20180821160600590?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p><hr><p>三、代码实战（二）<br>1、导入相关库文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> merge</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.layers.recurrent <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> attention_utils <span class="keyword">import</span> get_activations, get_data_recurrent</span><br><span class="line">INPUT_DIM = <span class="number">2</span></span><br><span class="line">TIME_STEPS = <span class="number">20</span></span><br><span class="line"><span class="comment"># if True, the attention vector is shared across the input_dimensions where the attention is applied.</span></span><br><span class="line">SINGLE_ATTENTION_VECTOR = <span class="keyword">False</span></span><br><span class="line">APPLY_ATTENTION_BEFORE_LSTM = <span class="keyword">False</span></span><br></pre></td></tr></table></figure></p><p>2、数据生成函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention_3d_block</span><span class="params">(inputs)</span>:</span></span><br><span class="line">    <span class="comment"># inputs.shape = (batch_size, time_steps, input_dim)</span></span><br><span class="line">    input_dim = int(inputs.shape[<span class="number">2</span>])</span><br><span class="line">    a = Permute((<span class="number">2</span>, <span class="number">1</span>))(inputs)</span><br><span class="line">    a = Reshape((input_dim, TIME_STEPS))(a) <span class="comment"># this line is not useful. It's just to know which dimension is what.</span></span><br><span class="line">    a = Dense(TIME_STEPS, activation=<span class="string">'softmax'</span>)(a)</span><br><span class="line">    <span class="keyword">if</span> SINGLE_ATTENTION_VECTOR:</span><br><span class="line">        a = Lambda(<span class="keyword">lambda</span> x: K.mean(x, axis=<span class="number">1</span>), name=<span class="string">'dim_reduction'</span>)(a)</span><br><span class="line">        a = RepeatVector(input_dim)(a)</span><br><span class="line">    a_probs = Permute((<span class="number">2</span>, <span class="number">1</span>), name=<span class="string">'attention_vec'</span>)(a)</span><br><span class="line">    output_attention_mul = merge([inputs, a_probs], name=<span class="string">'attention_mul'</span>, mode=<span class="string">'mul'</span>)</span><br><span class="line">    <span class="keyword">return</span> output_attention_mul</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_attention_applied_after_lstm</span><span class="params">()</span>:</span></span><br><span class="line">    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))</span><br><span class="line">    lstm_units = <span class="number">32</span></span><br><span class="line">    lstm_out = LSTM(lstm_units, return_sequences=<span class="keyword">True</span>)(inputs)</span><br><span class="line">    attention_mul = attention_3d_block(lstm_out)</span><br><span class="line">    attention_mul = Flatten()(attention_mul)</span><br><span class="line">    output = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(attention_mul)</span><br><span class="line">    model = Model(input=[inputs], output=output)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_attention_applied_before_lstm</span><span class="params">()</span>:</span></span><br><span class="line">    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))</span><br><span class="line">    attention_mul = attention_3d_block(inputs)</span><br><span class="line">    lstm_units = <span class="number">32</span></span><br><span class="line">    attention_mul = LSTM(lstm_units, return_sequences=<span class="keyword">False</span>)(attention_mul)</span><br><span class="line">    output = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(attention_mul)</span><br><span class="line">    model = Model(input=[inputs], output=output)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>3、主函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">   N = <span class="number">300000</span></span><br><span class="line">   <span class="comment"># N = 300 -&gt; too few = no training</span></span><br><span class="line">   inputs_1, outputs = get_data_recurrent(N, TIME_STEPS, INPUT_DIM)</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> APPLY_ATTENTION_BEFORE_LSTM:</span><br><span class="line">       m = model_attention_applied_before_lstm()</span><br><span class="line">   <span class="keyword">else</span>:</span><br><span class="line">       m = model_attention_applied_after_lstm()</span><br><span class="line"></span><br><span class="line">   m.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">   print(m.summary())</span><br><span class="line"></span><br><span class="line">   m.fit([inputs_1], outputs, epochs=<span class="number">1</span>, batch_size=<span class="number">64</span>, validation_split=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">   attention_vectors = []</span><br><span class="line">   <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">300</span>):</span><br><span class="line">       testing_inputs_1, testing_outputs = get_data_recurrent(<span class="number">1</span>, TIME_STEPS, INPUT_DIM)</span><br><span class="line">       attention_vector = np.mean(get_activations(m,</span><br><span class="line">                                                  testing_inputs_1,</span><br><span class="line">                                                  print_shape_only=<span class="keyword">True</span>,</span><br><span class="line">                                                  layer_name=<span class="string">'attention_vec'</span>)[<span class="number">0</span>], axis=<span class="number">2</span>).squeeze()</span><br><span class="line">       print(<span class="string">'attention ='</span>, attention_vector)</span><br><span class="line">       <span class="keyword">assert</span> (np.sum(attention_vector) - <span class="number">1.0</span>) &lt; <span class="number">1e-5</span></span><br><span class="line">       attention_vectors.append(attention_vector)</span><br><span class="line"></span><br><span class="line">   attention_vector_final = np.mean(np.array(attention_vectors), axis=<span class="number">0</span>)</span><br><span class="line">   <span class="comment"># plot part.</span></span><br><span class="line">   <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">   <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">   pd.DataFrame(attention_vector_final, columns=[<span class="string">'attention (%)'</span>]).plot(kind=<span class="string">'bar'</span>,</span><br><span class="line">                                                                        title=<span class="string">'Attention Mechanism as '</span></span><br><span class="line">                                                                              <span class="string">'a function of input'</span></span><br><span class="line">                                                                              <span class="string">' dimensions.'</span>)</span><br><span class="line">   plt.show()</span><br></pre></td></tr></table></figure></p><p>4、运行结果<br>代码中，attention_column为10，11，也就是说，label只与数据的第10，11个特征相关。从运行结果中可以看出，Attention权重成功地获取了这个信息。<br><img src="https://img-blog.csdn.net/20180821160943644?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppbnl1YW43NzA4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p><p>##<strong>相关代码放在代码仓库里哈，欢迎大家下载，这里附上地址：<a href="https://download.csdn.net/download/jinyuan7708/10617858" target="_blank" rel="noopener">基于Kears的Attention实战</a></strong></p>]]></content>
    
    <summary type="html">
    
      该教程是基于Kears的Attention实战
    
    </summary>
    
      <category term="深度学习" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>new Types</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/new-Types/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/new-Types/</id>
    <published>2018-08-24T03:24:45.000Z</published>
    <updated>2018-08-24T03:28:11.080Z</updated>
    
    <content type="html"><![CDATA[<p>我的分类是深度学习</p>]]></content>
    
    <summary type="html">
    
      Deep Learning
    
    </summary>
    
      <category term="深度学习" scheme="https://legendtianjin.github.io/NextLegend.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>“test”</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/%E2%80%9Ctest%E2%80%9D/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/“test”/</id>
    <published>2018-08-24T01:12:08.000Z</published>
    <updated>2018-08-24T01:13:31.493Z</updated>
    
    <content type="html"><![CDATA[<p>大家好，这是我的第一个hexo!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;大家好，这是我的第一个hexo!&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/hello-world/"/>
    <id>https://legendtianjin.github.io/NextLegend.github.io/2018/08/24/hello-world/</id>
    <published>2018-08-24T00:48:48.099Z</published>
    <updated>2018-08-24T07:29:11.776Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
